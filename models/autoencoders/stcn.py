# -*- coding: utf-8 -*-
"""STCN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DzouU6XEBwkIZ28jZQkF7fsRjuuYYGyu
"""

import numpy as np
import tensorflow as tf
import tensorflow.keras as keras

class TemporalBlock(tf.keras.Model):
  def __init__(self, dilation, nb_filters, kernel_size, 
				       padding, dropout=0.2): 
    super(TemporalBlock,self).__init__()
    init = keras.initializers.RandomNormal(mean=0.0, stddev=0.01)

    assert padding in ['causal','same']

    #First Block
    self.conv1 = keras.layers.Conv1D(filters=nb_filters,kernel_size = kernel_size,
                                     dilation_rate = dilation, 
                                     padding = padding,kernel_initializer=init)
    self.batch1 = keras.layers.BatchNormalization(axis = -1)
    self.activ1 = keras.layers.Activation('relu')
    self.drop1 = keras.layers.Dropout(rate=dropout)

    #Second Block
    self.conv2 = keras.layers.Conv1D(filters=nb_filters,kernel_size = kernel_size,
                                     dilation_rate = dilation, 
                                     padding = padding,kernel_initializer=init)
    self.batch2 = keras.layers.BatchNormalization(axis = -1)
    self.activ2 = keras.layers.Activation('relu')
    self.drop2 = keras.layers.Dropout(rate=dropout)

    self.downsample = keras.layers.Conv1D(filters=nb_filters, kernel_size=1, 
                                           padding = 'same',kernel_initializer=init)
    self.activ3 = keras.layers.Activation('relu')

  def call(self,x,training=True):
    prev_x = x 
    x = self.conv1(x)
    x = self.batch1(x)
    x = self.activ1(x) 
    x = self.drop1(x,training=training) 

    x = self.conv2(x)
    x = self.batch2(x)
    x = self.activ2(x)
    x = self.drop2(x,training=training)

    if prev_x.shape[-1] != x.shape[-1]:
      prev_x = self.downsample(prev_x)
    #assert prev_x.shape == x.shape

    # skip connection
    return self.activ3(prev_x +x)

class TCN(tf.keras.Model):
  def __init__(self,n_channels, kernel_size =2,dropout=0.2):
    super(TCN,self).__init__()
    assert isinstance(n_channels,list)

    tcn = tf.keras.Sequential()

    ## 
    n_levels = len(n_channels)
    for i in range(n_levels):
      dilation = 2**i
      tcn.add(TemporalBlock(dilation, n_channels[i], kernel_size, 
                      padding='causal', dropout=dropout))
    self.tcn = tcn
  def call(self, x, training=True):
    return self.tcn(x,training=training)

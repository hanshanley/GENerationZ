{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SELIFES_IC50Predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MJqXkIFLsiV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "1a8cf3be-57d3-4965-db68-be81ac09419c"
      },
      "source": [
        "# Initialize drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U84hRWOcLzzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "98bd80de-3b69-4527-cdaf-92de7898c7ef"
      },
      "source": [
        "# Move to Google Drive \n",
        "%cd drive\n",
        "%cd 'My Drive'\n",
        "%cd 'MSc Stats Dissertation'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/MSc Stats Dissertation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x55llLTZ63H8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b2f065f-02b8-4f97-e2cc-80652d6dafd4"
      },
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit\n",
        "!pip install selfies\n",
        "!pip install deepsmiles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-26 20:23:54--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n",
            "--2020-07-26 20:23:54--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "WARNING: md5sum mismatch of tar archive\n",
            "expected: 6e267728e74a7089e59c7d8c59d20e6b\n",
            "     got: ebb76490dfe6ce63b1dec5392631d80d  -\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.3.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.11.28-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.2-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_4\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_1\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.6-h0371630_2\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_1\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-45.2.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.42.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m25.492s\n",
            "user\t0m8.044s\n",
            "sys\t0m4.808s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.72.0               |   py37h9de70de_0         316 KB  conda-forge\n",
            "    boost-cpp-1.72.0           |       h8e57a91_0        21.8 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    hcf35c78_1003         1.5 MB  conda-forge\n",
            "    certifi-2020.6.20          |   py37hc8dfbb8_0         151 KB  conda-forge\n",
            "    conda-4.8.3                |   py37hc8dfbb8_1         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.2            |       he06d7ca_0         905 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.65.0                |       h6f030ca_0         3.5 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    jpeg-9d                    |       h516909a_0         266 KB  conda-forge\n",
            "    libblas-3.8.0              |      17_openblas          11 KB  conda-forge\n",
            "    libcblas-3.8.0             |      17_openblas          11 KB  conda-forge\n",
            "    libgfortran-ng-7.5.0       |      hdf63c60_10         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1006         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      17_openblas          11 KB  conda-forge\n",
            "    libopenblas-0.3.10         |pthreads_hb3c22a3_4         7.8 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_1         308 KB  conda-forge\n",
            "    libtiff-4.0.10             |    h9022e91_1002         555 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
            "    numpy-1.19.1               |   py37h8960a57_0         5.2 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1g             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-1.0.5               |   py37h0da4684_0        10.1 MB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pillow-6.2.1               |   py37h6b7be26_0         637 KB  conda-forge\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.19.1             |   py37h01af8b0_3          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
            "    pytz-2020.1                |     pyh9f0ad1d_0         227 KB  conda-forge\n",
            "    rdkit-2020.03.4            |   py37hdd87690_0        24.6 MB  conda-forge\n",
            "    tk-8.6.10                  |       hed695b0_0         3.2 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.3.3                 |                1        1023 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       112.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.72.0-py37h9de70de_0\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.72.0-h8e57a91_0\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hcf35c78_1003\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.2-he06d7ca_0\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.65.0-h6f030ca_0\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h516909a_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-17_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-17_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hdf63c60_10\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1006\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-17_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.10-pthreads_hb3c22a3_4\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_1\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.0.10-h9022e91_1002\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.19.1-py37h8960a57_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.0.5-py37h0da4684_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pillow             conda-forge/linux-64::pillow-6.2.1-py37h6b7be26_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.19.1-py37h01af8b0_3\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
            "  pytz               conda-forge/noarch::pytz-2020.1-pyh9f0ad1d_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2020.03.4-py37hdd87690_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.3.3-1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.6.20-hecda079_0\n",
            "  certifi              pkgs/main::certifi-2019.11.28-py37_0 --> conda-forge::certifi-2020.6.20-py37hc8dfbb8_0\n",
            "  conda                       pkgs/main::conda-4.8.2-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1g-h516909a_0\n",
            "  tk                         pkgs/main::tk-8.6.8-hbc83047_0 --> conda-forge::tk-8.6.10-hed695b0_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m46.406s\n",
            "user\t0m39.260s\n",
            "sys\t0m4.875s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98Zha14KJK8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o87R565WL3PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import math\n",
        "import tensorflow.keras.layers as layers\n",
        "from selfies import encoder, decoder\n",
        "import deepsmiles\n",
        "import rdkit\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcRdHP-hXh5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import Necessary Data for training\n",
        "train_smiles_X = np.load('./vocab/train_selfies_X.npy',allow_pickle=True)\n",
        "vocab =np.load('./vocab/selfies_vocab.npy',allow_pickle=True)\n",
        "vocab_index = np.load('./vocab/selfies_vocab_index.npy',allow_pickle=True)\n",
        "vocab = dict(vocab.ravel()[0])\n",
        "vocab_index = dict(vocab_index.ravel()[0])\n",
        "gene_expressions = np.load('./Datasets/ordered_gene_expressions.npy')\n",
        "ic50 = np.load('./Datasets/ordered_ic50.npy')\n",
        "smiles_pairs = np.load('./Datasets/ordered_smiles.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQPqDN0P3mow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Neccesary CONSTANTS\n",
        "BATCH_SIZE = 256\n",
        "VOCAB_SIZE = len(vocab_index)\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 1e-4\n",
        "DROP_OUT= 0.2\n",
        "EMBEDDING_DIM = 192  ## Embedding dim of the characters\n",
        "LATENT_DIM = 64\n",
        "PAD_LEN = 250\n",
        "MAX_LEN = PAD_LEN -1\n",
        "DROPOUT = 0.2\n",
        "TRAIN = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybFdEhBWIg-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Get randomized chemistry of different smiles strings\n",
        "## for training\n",
        "from rdkit import Chem\n",
        "def randomlabels(mol, N):\n",
        "  ans = set()\n",
        "  mol_ex = None\n",
        "  if mol.find('.') != -1:\n",
        "    mol_ex = mol[mol.find('.'):]\n",
        "    mol = mol[:mol.find('.')]\n",
        "  molt = Chem.MolFromSmiles(mol)\n",
        "  while len(ans) < N:\n",
        "    if mol_ex == None:\n",
        "      ans.add(Chem.MolToSmiles(molt,doRandom=True,canonical=True))\n",
        "    else:\n",
        "      ans.add(Chem.MolToSmiles((molt),doRandom=True,canonical=True)+mol_ex)\n",
        "  return sorted(list(ans))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMwLJHFe3Rvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## converts smiles to seflies smiles \n",
        "def get_smiles_from_selfies(selfies_list):\n",
        "  smiles = []\n",
        "  for selfie in selfies_list:\n",
        "    try:\n",
        "      smile = decoder(selfie)\n",
        "    except:\n",
        "      smile = None\n",
        "    smiles.append(smile)\n",
        "  return smiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d5vPcHW3Uye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def integer_encode_selfies(selfies,vocab_dict):\n",
        "  selfies_enc = []\n",
        "  for char in selfies:\n",
        "    selfies_enc.append(vocab_dict[char])\n",
        "  return selfies_enc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbAQYBoj3Wf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Splits the selfies <molecule> into a list of character strings.\n",
        "def split_selfie(molecule):\n",
        "  return re.findall(r'\\[.*?\\]|\\.', molecule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVe3u0cJ3Y1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Takes processed selfies smiles and returns the tokenized \n",
        "## versions of the selfies\n",
        "def tokenize_selfies(selfies):\n",
        "  char_list = split_selfie(selfies)\n",
        "  tokenized= []\n",
        "  tokenized.append('<BOS>')\n",
        "  i = 0 \n",
        "  while i < len(char_list):\n",
        "    char = char_list[i]\n",
        "    tokenized.append(char)\n",
        "    i = i+1\n",
        "  tokenized.append('<EOS>')\n",
        "  return tokenized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7tcLT523tHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "## replace Br and Cl with single letters\n",
        "def replace_halogens(string):\n",
        "  br = re.compile('Br')\n",
        "  cl = re.compile('Cl')\n",
        "  string = br.sub('R', string)\n",
        "  string = cl.sub('L', string)\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ub8iMmLgCQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Properly scale data \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(ic50.reshape(-1,1))\n",
        "ic50 = scaler.transform(ic50.reshape(-1,1))\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(gene_expressions)\n",
        "gene_expressions = scaler.transform(gene_expressions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17U96KOhIYeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_gene_expressions = []\n",
        "new_ic50 = []\n",
        "new_smile_pairs = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbYAQXRmITbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Get training data for guided training \n",
        "for i in range(len(smiles_pairs)):\n",
        "  if i % 10000 == 0:\n",
        "    print(i)\n",
        "  random_mols = randomlabels(smiles_pairs[i],8)\n",
        "  if SELFIES:\n",
        "    for mols in random_mols:\n",
        "      new_smile_pairs.append(encoder(mols))\n",
        "  else:\n",
        "    new_smile_pairs.extend(random_mols)\n",
        "  for j in range(len(random_mols)):\n",
        "    new_gene_expressions.append(gene_expressions[i])\n",
        "    new_ic50.append(ic50[i])\n",
        "gene_expressions= new_gene_expressions \n",
        "ic50 = new_ic50 \n",
        "smiles_pairs = new_smile_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysyHomZzBSWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smile_pair_tokens = []\n",
        "for smiles in smiles_pairs:\n",
        "  if SELFIES:\n",
        "    smile_pair_tokens.append(tokenize_selfies(smiles))\n",
        "  else:\n",
        "    smiles = replace_halogens(smiles)\n",
        "    smile_pair_tokens.append(tokenize_smiles(smiles))\n",
        "smile_pair_tokens = np.array(smile_pair_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA_yFDY0BwgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smiles_ordered = []\n",
        "for smiles in smile_pair_tokens:\n",
        "  if SELFIES:\n",
        "    smiles_ordered.append(integer_encode_selfies(smiles,vocab))\n",
        "  else:\n",
        "    smiles_ordered.append(integer_encode(smiles,vocab))\n",
        "smiles_ordered = np.array(smiles_ordered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoPj8xLkcico",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = tf.keras.preprocessing.sequence.pad_sequences(smiles_ordered,maxlen=PAD_LEN,padding='post')\n",
        "NUM_BATCHES = math.floor(len(t)/BATCH_SIZE )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B02etFYbcka2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_TRAIN_BATCH = math.floor(NUM_BATCHES*0.99)\n",
        "NUM_TEST_BATCH = math.floor(NUM_BATCHES*(0.01))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INWxAgpbcmDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_smiles = t[NUM_TRAIN_BATCH*BATCH_SIZE:(NUM_TEST_BATCH+NUM_TRAIN_BATCH)*BATCH_SIZE]\n",
        "train_smiles = t[:NUM_TRAIN_BATCH*BATCH_SIZE]\n",
        "\n",
        "test_genes = gene_expressions[NUM_TRAIN_BATCH*BATCH_SIZE:(NUM_TEST_BATCH+NUM_TRAIN_BATCH)*BATCH_SIZE]\n",
        "train_genes = gene_expressions[:NUM_TRAIN_BATCH*BATCH_SIZE]\n",
        "\n",
        "test_ic50 = ic50[NUM_TRAIN_BATCH*BATCH_SIZE:(NUM_TEST_BATCH+NUM_TRAIN_BATCH)*BATCH_SIZE]\n",
        "train_ic50 = ic50[:NUM_TRAIN_BATCH*BATCH_SIZE]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv9OD2EE7tpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import GANS.ic50vae as conv_smiles_vae\n",
        "smile_vae = conv_smiles_vae.SMILE_VAE(vocab_size= VOCAB_SIZE,embedding_dim=EMBEDDING_DIM, max_len= MAX_LEN, \n",
        "                     latent_dim = LATENT_DIM, recurrent_dropout = DROP_OUT,dropout_rate= DROP_OUT)\n",
        "if SELFIES:\n",
        "  smile_vae.load_weights('ic50g_selfies_conv_vae_weights')\n",
        "else:\n",
        "  smile_vae.load_weights('smiles_conv_vae_weights2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEg7ymxE9hQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mca_ic50 = ic50mca.IC50_MCA(vocab_size=VOCAB_SIZE, \n",
        "                    embedding_dim =EMBEDDING_DIM, num_genes =2128,\n",
        "                    hidden_dim = HIDDEN_DIM, max_len = MAX_LEN, \n",
        "                    latent_dim = LATENT_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQa2DzjXOnHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_smile_gene_ca(mca_ic50,smile_vae,\n",
        "                        train_smiles,train_genes,train_ic50,\n",
        "                        test_smiles, test_genes,test_ic50):\n",
        "  clip = -1\n",
        "  display_step = 100\n",
        "  STEPS_PER_EPOCH = train_smiles.shape[0]//BATCH_SIZE\n",
        "  TEST_STEPS = test_smiles.shape[0]//BATCH_SIZE\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-6)\n",
        "  \n",
        "  for epoch in range(EPOCHS):\n",
        "    ## Randomize the training process\n",
        "    indxs = np.arange(STEPS_PER_EPOCH)\n",
        "    np.random.shuffle(indxs)\n",
        "    total_train_loss = 0\n",
        "    for batch in range(STEPS_PER_EPOCH):\n",
        "      with tf.GradientTape() as tape:\n",
        "\n",
        "        ## Get relevant batch data\n",
        "        train_smiles_batch = np.array(train_smiles[indxs[batch]*BATCH_SIZE: indxs[batch]*BATCH_SIZE + BATCH_SIZE])\n",
        "        train_gene_batch = np.array(train_genes[indxs[batch]*BATCH_SIZE: indxs[batch]*BATCH_SIZE + BATCH_SIZE])\n",
        "        train_ic50_batch = np.array(train_ic50[indxs[batch]*BATCH_SIZE: indxs[batch]*BATCH_SIZE + BATCH_SIZE])\n",
        "        ## Get logits of the model \n",
        "        h, z_mean,z_log_var = smile_vae.encoder(train_smiles_batch[:,:-1])\n",
        "        z = tf.keras.layers.Lambda(smile_vae.encoder.sample, \n",
        "                               output_shape =(LATENT_DIM,))([z_mean,z_log_var])\n",
        "\n",
        "        ## Get ic50 prediction              \n",
        "        ic50_pred = mca_ic50(encoded_smiles = z_mean, genes = train_gene_batch)\n",
        "        loss_op = tf.reduce_sum(tf.keras.losses.MSE(train_ic50_batch,ic50_pred))\n",
        "        total_train_loss += loss_op\n",
        "        \n",
        "      ## Apply gradients \n",
        "      gradients = tape.gradient(loss_op, mca_ic50.trainable_variables)\n",
        "      if clip != -1:\n",
        "        gradients, _ = tf.clip_by_global_norm(gradients, clip) \n",
        "      optimizer.apply_gradients(zip(gradients, mca_ic50.trainable_variables))\n",
        "\n",
        "      ## Diplay training loss information ##\n",
        "      if batch % display_step == 0 or batch == 1:\n",
        "\n",
        "        ### Get logits for test data\n",
        "        rand_int =np.random.randint(low=0,high = TEST_STEPS)\n",
        "        test_smiles_batch = np.array(test_smiles[rand_int*BATCH_SIZE: rand_int*BATCH_SIZE + BATCH_SIZE])\n",
        "        test_gene_batch = np.array(test_genes[rand_int*BATCH_SIZE: rand_int*BATCH_SIZE + BATCH_SIZE])\n",
        "        test_ic50_batch = np.array(test_ic50[rand_int*BATCH_SIZE: rand_int*BATCH_SIZE + BATCH_SIZE])\n",
        "\n",
        "        ### Encode data using encoder \n",
        "        h, z_mean,z_log_var = smile_vae.encoder(test_smiles_batch[:,:-1])\n",
        "        z = tf.keras.layers.Lambda(smile_vae.encoder.sample, \n",
        "                               output_shape =(LATENT_DIM,))([z_mean,z_log_var])\n",
        "\n",
        "        ## Get prediction  \n",
        "        ic50_pred_test = mca_ic50(encoded_smiles = z_mean,\n",
        "                             genes = test_gene_batch,training=False)\n",
        "\n",
        "        ### Print out test accuracy on model \n",
        "        test_loss = tf.reduce_sum(tf.keras.losses.MSE(test_ic50_batch,\n",
        "                                                     ic50_pred_test))\n",
        "\n",
        "        print(\"Step \" + str(batch) + \", Training Loss = \" + \\\n",
        "                \"{:.3f}\".format(tf.reduce_mean(loss_op)) + \", Test Loss = \" + \\\n",
        "                \"{:.3f}\".format(tf.reduce_mean(test_loss)))\n",
        "      if  (batch) == STEPS_PER_EPOCH-1:\n",
        "        print(\"TOTAL TRAINING LOSS \" + \"{:.3f}\".format(tf.reduce_sum(total_train_loss)))\n",
        "      if  (batch) % 3000 == 0:\n",
        "        mca_ic50.save_weights('ic50network_selfies_ic50g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5WjxAV9Urxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb9db53f-9ee4-4f3d-93d7-530daec9b1c6"
      },
      "source": [
        "if TRAIN:\n",
        "  train_smile_gene_ca(mca_ic50,smile_vae,\n",
        "                        train_smiles,train_genes,train_ic50,\n",
        "                        test_smiles, test_genes,test_ic50)\n",
        "else:\n",
        "  mca_ic50.load_weights('ic50network_selfies_ic50g')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HERE\n",
            "Step 0, Training Loss = 94.815, Test Loss = 128.445\n",
            "Step 1, Training Loss = 152.783, Test Loss = 108.657\n",
            "Step 100, Training Loss = 14.438, Test Loss = 8.992\n",
            "Step 200, Training Loss = 7.997, Test Loss = 7.166\n",
            "Step 300, Training Loss = 10.095, Test Loss = 6.222\n",
            "Step 400, Training Loss = 5.869, Test Loss = 5.126\n",
            "Step 500, Training Loss = 5.062, Test Loss = 5.482\n",
            "Step 600, Training Loss = 6.577, Test Loss = 5.190\n",
            "Step 700, Training Loss = 4.620, Test Loss = 4.896\n",
            "Step 800, Training Loss = 5.242, Test Loss = 5.035\n",
            "Step 900, Training Loss = 5.991, Test Loss = 4.571\n",
            "Step 1000, Training Loss = 6.230, Test Loss = 4.978\n",
            "Step 1100, Training Loss = 2.892, Test Loss = 4.632\n",
            "Step 1200, Training Loss = 3.160, Test Loss = 4.239\n",
            "Step 1300, Training Loss = 4.498, Test Loss = 5.152\n",
            "Step 1400, Training Loss = 4.295, Test Loss = 4.759\n",
            "Step 1500, Training Loss = 3.999, Test Loss = 3.943\n",
            "Step 1600, Training Loss = 4.376, Test Loss = 4.527\n",
            "Step 1700, Training Loss = 3.281, Test Loss = 4.465\n",
            "Step 1800, Training Loss = 2.078, Test Loss = 5.247\n",
            "Step 1900, Training Loss = 4.808, Test Loss = 4.253\n",
            "Step 2000, Training Loss = 2.893, Test Loss = 4.523\n",
            "Step 2100, Training Loss = 2.758, Test Loss = 4.596\n",
            "Step 2200, Training Loss = 3.773, Test Loss = 4.326\n",
            "Step 2300, Training Loss = 2.570, Test Loss = 4.737\n",
            "Step 2400, Training Loss = 4.195, Test Loss = 4.519\n",
            "Step 2500, Training Loss = 3.170, Test Loss = 4.089\n",
            "Step 2600, Training Loss = 3.885, Test Loss = 5.695\n",
            "Step 2700, Training Loss = 2.586, Test Loss = 4.914\n",
            "Step 2800, Training Loss = 5.461, Test Loss = 4.143\n",
            "Step 2900, Training Loss = 2.787, Test Loss = 3.622\n",
            "Step 3000, Training Loss = 4.827, Test Loss = 4.347\n",
            "Step 3100, Training Loss = 4.366, Test Loss = 4.555\n",
            "Step 3200, Training Loss = 1.589, Test Loss = 5.254\n",
            "Step 3300, Training Loss = 4.118, Test Loss = 4.696\n",
            "Step 3400, Training Loss = 2.721, Test Loss = 4.417\n",
            "Step 3500, Training Loss = 4.417, Test Loss = 4.927\n",
            "Step 3600, Training Loss = 4.892, Test Loss = 4.992\n",
            "Step 3700, Training Loss = 3.142, Test Loss = 3.900\n",
            "Step 3800, Training Loss = 3.388, Test Loss = 5.314\n",
            "Step 3900, Training Loss = 2.821, Test Loss = 4.709\n",
            "Step 4000, Training Loss = 3.219, Test Loss = 4.425\n",
            "Step 4100, Training Loss = 5.226, Test Loss = 2.974\n",
            "Step 4200, Training Loss = 3.687, Test Loss = 3.430\n",
            "Step 4300, Training Loss = 6.543, Test Loss = 5.320\n",
            "Step 4400, Training Loss = 3.760, Test Loss = 3.935\n",
            "Step 4500, Training Loss = 4.172, Test Loss = 3.135\n",
            "Step 4600, Training Loss = 4.372, Test Loss = 4.387\n",
            "TOTAL TRAINING LOSS 21556.699\n",
            "Step 0, Training Loss = 2.759, Test Loss = 3.098\n",
            "Step 1, Training Loss = 3.025, Test Loss = 3.105\n",
            "Step 100, Training Loss = 3.790, Test Loss = 2.604\n",
            "Step 200, Training Loss = 2.341, Test Loss = 3.467\n",
            "Step 300, Training Loss = 2.436, Test Loss = 4.471\n",
            "Step 400, Training Loss = 2.750, Test Loss = 3.926\n",
            "Step 500, Training Loss = 1.708, Test Loss = 4.280\n",
            "Step 600, Training Loss = 3.594, Test Loss = 3.864\n",
            "Step 700, Training Loss = 2.410, Test Loss = 4.999\n",
            "Step 800, Training Loss = 3.253, Test Loss = 5.247\n",
            "Step 900, Training Loss = 3.870, Test Loss = 4.176\n",
            "Step 1000, Training Loss = 3.956, Test Loss = 4.561\n",
            "Step 1100, Training Loss = 2.551, Test Loss = 4.394\n",
            "Step 1200, Training Loss = 3.444, Test Loss = 4.497\n",
            "Step 1300, Training Loss = 4.077, Test Loss = 3.873\n",
            "Step 1400, Training Loss = 3.822, Test Loss = 3.734\n",
            "Step 1500, Training Loss = 2.683, Test Loss = 3.852\n",
            "Step 1600, Training Loss = 2.695, Test Loss = 3.132\n",
            "Step 1700, Training Loss = 3.283, Test Loss = 3.082\n",
            "Step 1800, Training Loss = 3.653, Test Loss = 3.341\n",
            "Step 1900, Training Loss = 3.446, Test Loss = 4.087\n",
            "Step 2000, Training Loss = 3.333, Test Loss = 4.181\n",
            "Step 2100, Training Loss = 2.646, Test Loss = 3.563\n",
            "Step 2200, Training Loss = 3.539, Test Loss = 3.985\n",
            "Step 2300, Training Loss = 2.475, Test Loss = 4.739\n",
            "Step 2400, Training Loss = 2.312, Test Loss = 3.317\n",
            "Step 2500, Training Loss = 1.788, Test Loss = 4.366\n",
            "Step 2600, Training Loss = 3.561, Test Loss = 4.061\n",
            "Step 2700, Training Loss = 3.558, Test Loss = 3.900\n",
            "Step 2800, Training Loss = 3.617, Test Loss = 4.350\n",
            "Step 2900, Training Loss = 3.741, Test Loss = 3.921\n",
            "Step 3000, Training Loss = 3.135, Test Loss = 3.979\n",
            "Step 3100, Training Loss = 2.144, Test Loss = 4.502\n",
            "Step 3200, Training Loss = 2.367, Test Loss = 3.358\n",
            "Step 3300, Training Loss = 3.540, Test Loss = 3.541\n",
            "Step 3400, Training Loss = 2.091, Test Loss = 4.024\n",
            "Step 3500, Training Loss = 2.277, Test Loss = 3.856\n",
            "Step 3600, Training Loss = 3.404, Test Loss = 3.919\n",
            "Step 3700, Training Loss = 3.192, Test Loss = 3.462\n",
            "Step 3800, Training Loss = 2.611, Test Loss = 3.071\n",
            "Step 3900, Training Loss = 3.237, Test Loss = 2.770\n",
            "Step 4000, Training Loss = 3.879, Test Loss = 3.837\n",
            "Step 4100, Training Loss = 2.049, Test Loss = 4.359\n",
            "Step 4200, Training Loss = 2.772, Test Loss = 3.443\n",
            "Step 4300, Training Loss = 2.993, Test Loss = 3.384\n",
            "Step 4400, Training Loss = 2.409, Test Loss = 3.267\n",
            "Step 4500, Training Loss = 3.114, Test Loss = 4.669\n",
            "Step 4600, Training Loss = 3.403, Test Loss = 3.694\n",
            "TOTAL TRAINING LOSS 14413.456\n",
            "Step 0, Training Loss = 3.059, Test Loss = 4.760\n",
            "Step 1, Training Loss = 2.009, Test Loss = 4.665\n",
            "Step 100, Training Loss = 2.363, Test Loss = 2.977\n",
            "Step 200, Training Loss = 3.785, Test Loss = 2.899\n",
            "Step 300, Training Loss = 2.233, Test Loss = 3.516\n",
            "Step 400, Training Loss = 2.933, Test Loss = 2.786\n",
            "Step 500, Training Loss = 3.318, Test Loss = 3.255\n",
            "Step 600, Training Loss = 2.860, Test Loss = 2.564\n",
            "Step 700, Training Loss = 3.390, Test Loss = 3.825\n",
            "Step 800, Training Loss = 2.775, Test Loss = 2.469\n",
            "Step 900, Training Loss = 1.810, Test Loss = 3.221\n",
            "Step 1000, Training Loss = 2.344, Test Loss = 4.726\n",
            "Step 1100, Training Loss = 3.092, Test Loss = 2.970\n",
            "Step 1200, Training Loss = 3.298, Test Loss = 3.261\n",
            "Step 1300, Training Loss = 2.678, Test Loss = 3.742\n",
            "Step 1400, Training Loss = 2.667, Test Loss = 3.397\n",
            "Step 1500, Training Loss = 3.875, Test Loss = 3.876\n",
            "Step 1600, Training Loss = 3.713, Test Loss = 4.151\n",
            "Step 1700, Training Loss = 3.101, Test Loss = 3.459\n",
            "Step 1800, Training Loss = 3.757, Test Loss = 2.912\n",
            "Step 1900, Training Loss = 2.145, Test Loss = 4.023\n",
            "Step 2000, Training Loss = 2.648, Test Loss = 3.452\n",
            "Step 2100, Training Loss = 3.276, Test Loss = 3.457\n",
            "Step 2200, Training Loss = 2.273, Test Loss = 3.874\n",
            "Step 2300, Training Loss = 3.288, Test Loss = 3.540\n",
            "Step 2400, Training Loss = 2.054, Test Loss = 3.232\n",
            "Step 2500, Training Loss = 3.250, Test Loss = 3.831\n",
            "Step 2600, Training Loss = 2.905, Test Loss = 3.479\n",
            "Step 2700, Training Loss = 4.050, Test Loss = 4.013\n",
            "Step 2800, Training Loss = 3.807, Test Loss = 3.819\n",
            "Step 2900, Training Loss = 2.164, Test Loss = 3.544\n",
            "Step 3000, Training Loss = 1.447, Test Loss = 4.103\n",
            "Step 3100, Training Loss = 3.438, Test Loss = 3.545\n",
            "Step 3200, Training Loss = 2.670, Test Loss = 4.287\n",
            "Step 3300, Training Loss = 2.914, Test Loss = 3.573\n",
            "Step 3400, Training Loss = 2.358, Test Loss = 2.916\n",
            "Step 3500, Training Loss = 1.999, Test Loss = 3.403\n",
            "Step 3600, Training Loss = 2.159, Test Loss = 3.390\n",
            "Step 3700, Training Loss = 3.440, Test Loss = 4.292\n",
            "Step 3800, Training Loss = 1.770, Test Loss = 3.883\n",
            "Step 3900, Training Loss = 1.470, Test Loss = 3.644\n",
            "Step 4000, Training Loss = 2.545, Test Loss = 3.835\n",
            "Step 4100, Training Loss = 2.383, Test Loss = 3.637\n",
            "Step 4200, Training Loss = 2.248, Test Loss = 3.720\n",
            "Step 4300, Training Loss = 3.073, Test Loss = 3.490\n",
            "Step 4400, Training Loss = 2.949, Test Loss = 3.199\n",
            "Step 4500, Training Loss = 2.406, Test Loss = 3.953\n",
            "Step 4600, Training Loss = 2.965, Test Loss = 3.899\n",
            "TOTAL TRAINING LOSS 12420.203\n",
            "Step 0, Training Loss = 3.288, Test Loss = 2.831\n",
            "Step 1, Training Loss = 3.710, Test Loss = 2.772\n",
            "Step 100, Training Loss = 2.345, Test Loss = 4.049\n",
            "Step 200, Training Loss = 2.543, Test Loss = 3.198\n",
            "Step 300, Training Loss = 1.469, Test Loss = 3.763\n",
            "Step 400, Training Loss = 3.075, Test Loss = 3.041\n",
            "Step 500, Training Loss = 1.777, Test Loss = 2.532\n",
            "Step 600, Training Loss = 2.120, Test Loss = 2.838\n",
            "Step 700, Training Loss = 2.582, Test Loss = 3.268\n",
            "Step 800, Training Loss = 2.043, Test Loss = 4.218\n",
            "Step 900, Training Loss = 0.794, Test Loss = 3.607\n",
            "Step 1000, Training Loss = 1.171, Test Loss = 3.617\n",
            "Step 1100, Training Loss = 3.127, Test Loss = 3.598\n",
            "Step 1200, Training Loss = 2.455, Test Loss = 3.480\n",
            "Step 1300, Training Loss = 3.483, Test Loss = 4.021\n",
            "Step 1400, Training Loss = 1.991, Test Loss = 3.799\n",
            "Step 1500, Training Loss = 3.165, Test Loss = 3.344\n",
            "Step 1600, Training Loss = 1.990, Test Loss = 3.333\n",
            "Step 1700, Training Loss = 2.820, Test Loss = 4.155\n",
            "Step 1800, Training Loss = 2.311, Test Loss = 3.606\n",
            "Step 1900, Training Loss = 2.206, Test Loss = 4.689\n",
            "Step 2000, Training Loss = 1.829, Test Loss = 3.238\n",
            "Step 2100, Training Loss = 1.904, Test Loss = 2.922\n",
            "Step 2200, Training Loss = 1.465, Test Loss = 2.887\n",
            "Step 2300, Training Loss = 2.252, Test Loss = 3.585\n",
            "Step 2400, Training Loss = 1.652, Test Loss = 3.858\n",
            "Step 2500, Training Loss = 2.162, Test Loss = 3.674\n",
            "Step 2600, Training Loss = 3.137, Test Loss = 2.545\n",
            "Step 2700, Training Loss = 1.749, Test Loss = 3.389\n",
            "Step 2800, Training Loss = 2.080, Test Loss = 3.316\n",
            "Step 2900, Training Loss = 2.028, Test Loss = 4.040\n",
            "Step 3000, Training Loss = 1.146, Test Loss = 3.300\n",
            "Step 3100, Training Loss = 2.052, Test Loss = 2.936\n",
            "Step 3200, Training Loss = 2.549, Test Loss = 3.272\n",
            "Step 3300, Training Loss = 2.284, Test Loss = 3.074\n",
            "Step 3400, Training Loss = 2.906, Test Loss = 3.527\n",
            "Step 3500, Training Loss = 2.342, Test Loss = 2.623\n",
            "Step 3600, Training Loss = 1.618, Test Loss = 3.082\n",
            "Step 3700, Training Loss = 1.971, Test Loss = 3.122\n",
            "Step 3800, Training Loss = 2.059, Test Loss = 3.119\n",
            "Step 3900, Training Loss = 2.694, Test Loss = 2.693\n",
            "Step 4000, Training Loss = 2.892, Test Loss = 2.890\n",
            "Step 4100, Training Loss = 2.624, Test Loss = 3.464\n",
            "Step 4200, Training Loss = 2.386, Test Loss = 3.531\n",
            "Step 4300, Training Loss = 2.369, Test Loss = 3.523\n",
            "Step 4400, Training Loss = 1.425, Test Loss = 3.439\n",
            "Step 4500, Training Loss = 1.718, Test Loss = 3.626\n",
            "Step 4600, Training Loss = 2.120, Test Loss = 3.496\n",
            "TOTAL TRAINING LOSS 11339.213\n",
            "Step 0, Training Loss = 1.873, Test Loss = 3.429\n",
            "Step 1, Training Loss = 1.284, Test Loss = 3.454\n",
            "Step 100, Training Loss = 2.051, Test Loss = 3.188\n",
            "Step 200, Training Loss = 1.862, Test Loss = 3.288\n",
            "Step 300, Training Loss = 2.728, Test Loss = 4.364\n",
            "Step 400, Training Loss = 2.490, Test Loss = 3.231\n",
            "Step 500, Training Loss = 2.402, Test Loss = 3.330\n",
            "Step 600, Training Loss = 2.317, Test Loss = 3.363\n",
            "Step 700, Training Loss = 2.562, Test Loss = 3.497\n",
            "Step 800, Training Loss = 2.270, Test Loss = 2.904\n",
            "Step 900, Training Loss = 1.990, Test Loss = 3.233\n",
            "Step 1000, Training Loss = 3.112, Test Loss = 3.282\n",
            "Step 1100, Training Loss = 1.888, Test Loss = 2.956\n",
            "Step 1200, Training Loss = 1.932, Test Loss = 3.507\n",
            "Step 1300, Training Loss = 2.653, Test Loss = 3.536\n",
            "Step 1400, Training Loss = 1.992, Test Loss = 3.117\n",
            "Step 1500, Training Loss = 3.195, Test Loss = 2.975\n",
            "Step 1600, Training Loss = 2.150, Test Loss = 3.189\n",
            "Step 1700, Training Loss = 1.408, Test Loss = 3.534\n",
            "Step 1800, Training Loss = 2.160, Test Loss = 3.358\n",
            "Step 1900, Training Loss = 2.064, Test Loss = 3.180\n",
            "Step 2000, Training Loss = 3.127, Test Loss = 3.801\n",
            "Step 2100, Training Loss = 1.162, Test Loss = 4.386\n",
            "Step 2200, Training Loss = 2.561, Test Loss = 3.329\n",
            "Step 2300, Training Loss = 2.638, Test Loss = 2.873\n",
            "Step 2400, Training Loss = 3.348, Test Loss = 3.399\n",
            "Step 2500, Training Loss = 1.797, Test Loss = 3.147\n",
            "Step 2600, Training Loss = 1.580, Test Loss = 3.178\n",
            "Step 2700, Training Loss = 1.556, Test Loss = 3.231\n",
            "Step 2800, Training Loss = 2.695, Test Loss = 3.035\n",
            "Step 2900, Training Loss = 2.228, Test Loss = 3.247\n",
            "Step 3000, Training Loss = 1.832, Test Loss = 3.703\n",
            "Step 3100, Training Loss = 2.558, Test Loss = 3.707\n",
            "Step 3200, Training Loss = 2.548, Test Loss = 3.620\n",
            "Step 3300, Training Loss = 3.123, Test Loss = 4.182\n",
            "Step 3400, Training Loss = 2.077, Test Loss = 4.356\n",
            "Step 3500, Training Loss = 1.854, Test Loss = 3.088\n",
            "Step 3600, Training Loss = 3.481, Test Loss = 2.780\n",
            "Step 3700, Training Loss = 2.875, Test Loss = 3.189\n",
            "Step 3800, Training Loss = 2.510, Test Loss = 3.147\n",
            "Step 3900, Training Loss = 1.689, Test Loss = 3.206\n",
            "Step 4000, Training Loss = 2.516, Test Loss = 3.231\n",
            "Step 4100, Training Loss = 2.500, Test Loss = 3.465\n",
            "Step 4200, Training Loss = 2.482, Test Loss = 2.711\n",
            "Step 4300, Training Loss = 1.567, Test Loss = 2.571\n",
            "Step 4400, Training Loss = 2.007, Test Loss = 2.844\n",
            "Step 4500, Training Loss = 1.804, Test Loss = 3.408\n",
            "Step 4600, Training Loss = 2.237, Test Loss = 4.057\n",
            "TOTAL TRAINING LOSS 10561.963\n",
            "Step 0, Training Loss = 2.150, Test Loss = 3.440\n",
            "Step 1, Training Loss = 2.952, Test Loss = 3.381\n",
            "Step 100, Training Loss = 1.783, Test Loss = 2.650\n",
            "Step 200, Training Loss = 2.177, Test Loss = 3.051\n",
            "Step 300, Training Loss = 3.591, Test Loss = 3.606\n",
            "Step 400, Training Loss = 3.461, Test Loss = 2.768\n",
            "Step 500, Training Loss = 2.736, Test Loss = 3.007\n",
            "Step 600, Training Loss = 1.798, Test Loss = 3.261\n",
            "Step 700, Training Loss = 1.118, Test Loss = 3.283\n",
            "Step 800, Training Loss = 1.401, Test Loss = 2.821\n",
            "Step 900, Training Loss = 1.137, Test Loss = 2.940\n",
            "Step 1000, Training Loss = 1.785, Test Loss = 2.842\n",
            "Step 1100, Training Loss = 2.752, Test Loss = 2.899\n",
            "Step 1200, Training Loss = 2.096, Test Loss = 3.264\n",
            "Step 1300, Training Loss = 1.515, Test Loss = 3.142\n",
            "Step 1400, Training Loss = 3.410, Test Loss = 3.108\n",
            "Step 1500, Training Loss = 1.909, Test Loss = 3.249\n",
            "Step 1600, Training Loss = 3.745, Test Loss = 3.555\n",
            "Step 1700, Training Loss = 2.956, Test Loss = 3.836\n",
            "Step 1800, Training Loss = 2.460, Test Loss = 4.107\n",
            "Step 1900, Training Loss = 1.412, Test Loss = 3.621\n",
            "Step 2000, Training Loss = 2.212, Test Loss = 3.091\n",
            "Step 2100, Training Loss = 2.238, Test Loss = 3.331\n",
            "Step 2200, Training Loss = 3.413, Test Loss = 2.454\n",
            "Step 2300, Training Loss = 2.671, Test Loss = 2.385\n",
            "Step 2400, Training Loss = 2.426, Test Loss = 3.462\n",
            "Step 2500, Training Loss = 1.955, Test Loss = 3.013\n",
            "Step 2600, Training Loss = 1.651, Test Loss = 3.762\n",
            "Step 2700, Training Loss = 2.257, Test Loss = 3.207\n",
            "Step 2800, Training Loss = 1.470, Test Loss = 2.981\n",
            "Step 2900, Training Loss = 1.809, Test Loss = 3.116\n",
            "Step 3000, Training Loss = 3.815, Test Loss = 3.056\n",
            "Step 3100, Training Loss = 3.136, Test Loss = 3.343\n",
            "Step 3200, Training Loss = 1.814, Test Loss = 2.611\n",
            "Step 3300, Training Loss = 2.373, Test Loss = 2.345\n",
            "Step 3400, Training Loss = 3.050, Test Loss = 3.243\n",
            "Step 3500, Training Loss = 1.961, Test Loss = 2.812\n",
            "Step 3600, Training Loss = 2.454, Test Loss = 2.994\n",
            "Step 3700, Training Loss = 1.849, Test Loss = 2.707\n",
            "Step 3800, Training Loss = 1.913, Test Loss = 3.334\n",
            "Step 3900, Training Loss = 2.459, Test Loss = 3.260\n",
            "Step 4000, Training Loss = 2.925, Test Loss = 3.002\n",
            "Step 4100, Training Loss = 2.376, Test Loss = 3.046\n",
            "Step 4200, Training Loss = 1.767, Test Loss = 2.252\n",
            "Step 4300, Training Loss = 2.420, Test Loss = 3.285\n",
            "Step 4400, Training Loss = 2.411, Test Loss = 2.598\n",
            "Step 4500, Training Loss = 1.406, Test Loss = 3.379\n",
            "Step 4600, Training Loss = 1.905, Test Loss = 2.834\n",
            "TOTAL TRAINING LOSS 9883.350\n",
            "Step 0, Training Loss = 1.721, Test Loss = 3.081\n",
            "Step 1, Training Loss = 2.052, Test Loss = 3.116\n",
            "Step 100, Training Loss = 2.341, Test Loss = 3.543\n",
            "Step 200, Training Loss = 2.157, Test Loss = 2.978\n",
            "Step 300, Training Loss = 2.225, Test Loss = 3.419\n",
            "Step 400, Training Loss = 1.829, Test Loss = 2.575\n",
            "Step 500, Training Loss = 1.932, Test Loss = 3.434\n",
            "Step 600, Training Loss = 1.740, Test Loss = 3.485\n",
            "Step 700, Training Loss = 1.853, Test Loss = 3.061\n",
            "Step 800, Training Loss = 1.425, Test Loss = 3.348\n",
            "Step 900, Training Loss = 2.443, Test Loss = 3.587\n",
            "Step 1000, Training Loss = 2.762, Test Loss = 2.732\n",
            "Step 1100, Training Loss = 2.319, Test Loss = 3.024\n",
            "Step 1200, Training Loss = 1.495, Test Loss = 2.334\n",
            "Step 1300, Training Loss = 1.545, Test Loss = 2.855\n",
            "Step 1400, Training Loss = 1.612, Test Loss = 2.313\n",
            "Step 1500, Training Loss = 1.188, Test Loss = 3.333\n",
            "Step 1600, Training Loss = 2.442, Test Loss = 2.890\n",
            "Step 1700, Training Loss = 2.384, Test Loss = 2.587\n",
            "Step 1800, Training Loss = 1.390, Test Loss = 3.040\n",
            "Step 1900, Training Loss = 1.407, Test Loss = 2.773\n",
            "Step 2000, Training Loss = 2.620, Test Loss = 2.764\n",
            "Step 2100, Training Loss = 2.480, Test Loss = 3.552\n",
            "Step 2200, Training Loss = 1.855, Test Loss = 2.935\n",
            "Step 2300, Training Loss = 1.736, Test Loss = 2.602\n",
            "Step 2400, Training Loss = 1.497, Test Loss = 2.866\n",
            "Step 2500, Training Loss = 1.214, Test Loss = 2.709\n",
            "Step 2600, Training Loss = 1.553, Test Loss = 3.009\n",
            "Step 2700, Training Loss = 1.746, Test Loss = 2.889\n",
            "Step 2800, Training Loss = 1.923, Test Loss = 2.865\n",
            "Step 2900, Training Loss = 2.731, Test Loss = 2.930\n",
            "Step 3000, Training Loss = 1.987, Test Loss = 2.536\n",
            "Step 3100, Training Loss = 2.212, Test Loss = 2.817\n",
            "Step 3200, Training Loss = 1.753, Test Loss = 3.260\n",
            "Step 3300, Training Loss = 1.651, Test Loss = 3.555\n",
            "Step 3400, Training Loss = 2.033, Test Loss = 3.221\n",
            "Step 3500, Training Loss = 1.046, Test Loss = 2.418\n",
            "Step 3600, Training Loss = 2.521, Test Loss = 2.571\n",
            "Step 3700, Training Loss = 1.731, Test Loss = 2.916\n",
            "Step 3800, Training Loss = 1.722, Test Loss = 2.475\n",
            "Step 3900, Training Loss = 1.857, Test Loss = 2.715\n",
            "Step 4000, Training Loss = 2.498, Test Loss = 3.389\n",
            "Step 4100, Training Loss = 2.823, Test Loss = 2.911\n",
            "Step 4200, Training Loss = 1.538, Test Loss = 2.197\n",
            "Step 4300, Training Loss = 2.250, Test Loss = 3.168\n",
            "Step 4400, Training Loss = 2.300, Test Loss = 2.671\n",
            "Step 4500, Training Loss = 1.676, Test Loss = 3.051\n",
            "Step 4600, Training Loss = 2.876, Test Loss = 2.916\n",
            "TOTAL TRAINING LOSS 9376.107\n",
            "Step 0, Training Loss = 1.272, Test Loss = 2.849\n",
            "Step 1, Training Loss = 2.628, Test Loss = 2.840\n",
            "Step 100, Training Loss = 2.196, Test Loss = 2.381\n",
            "Step 200, Training Loss = 1.962, Test Loss = 2.956\n",
            "Step 300, Training Loss = 1.777, Test Loss = 3.254\n",
            "Step 400, Training Loss = 1.714, Test Loss = 2.637\n",
            "Step 500, Training Loss = 1.305, Test Loss = 3.372\n",
            "Step 600, Training Loss = 1.496, Test Loss = 3.069\n",
            "Step 700, Training Loss = 2.846, Test Loss = 2.585\n",
            "Step 800, Training Loss = 2.083, Test Loss = 2.661\n",
            "Step 900, Training Loss = 2.393, Test Loss = 2.973\n",
            "Step 1000, Training Loss = 1.706, Test Loss = 2.511\n",
            "Step 1100, Training Loss = 1.445, Test Loss = 2.856\n",
            "Step 1200, Training Loss = 1.493, Test Loss = 2.625\n",
            "Step 1300, Training Loss = 1.272, Test Loss = 2.700\n",
            "Step 1400, Training Loss = 1.466, Test Loss = 2.701\n",
            "Step 1500, Training Loss = 3.371, Test Loss = 2.676\n",
            "Step 1600, Training Loss = 1.586, Test Loss = 3.251\n",
            "Step 1700, Training Loss = 1.592, Test Loss = 2.803\n",
            "Step 1800, Training Loss = 3.632, Test Loss = 2.862\n",
            "Step 1900, Training Loss = 2.274, Test Loss = 2.384\n",
            "Step 2000, Training Loss = 1.974, Test Loss = 2.409\n",
            "Step 2100, Training Loss = 2.018, Test Loss = 3.116\n",
            "Step 2200, Training Loss = 2.078, Test Loss = 3.194\n",
            "Step 2300, Training Loss = 2.214, Test Loss = 3.638\n",
            "Step 2400, Training Loss = 1.824, Test Loss = 3.492\n",
            "Step 2500, Training Loss = 2.749, Test Loss = 3.540\n",
            "Step 2600, Training Loss = 2.030, Test Loss = 2.915\n",
            "Step 2700, Training Loss = 1.493, Test Loss = 2.999\n",
            "Step 2800, Training Loss = 1.807, Test Loss = 2.998\n",
            "Step 2900, Training Loss = 1.622, Test Loss = 3.040\n",
            "Step 3000, Training Loss = 1.725, Test Loss = 3.294\n",
            "Step 3100, Training Loss = 1.518, Test Loss = 2.698\n",
            "Step 3200, Training Loss = 1.495, Test Loss = 3.008\n",
            "Step 3300, Training Loss = 1.398, Test Loss = 2.788\n",
            "Step 3400, Training Loss = 1.131, Test Loss = 2.685\n",
            "Step 3500, Training Loss = 2.120, Test Loss = 2.733\n",
            "Step 3600, Training Loss = 1.627, Test Loss = 3.103\n",
            "Step 3700, Training Loss = 1.629, Test Loss = 2.883\n",
            "Step 3800, Training Loss = 1.789, Test Loss = 2.856\n",
            "Step 3900, Training Loss = 1.706, Test Loss = 2.294\n",
            "Step 4000, Training Loss = 2.701, Test Loss = 2.890\n",
            "Step 4100, Training Loss = 2.473, Test Loss = 3.024\n",
            "Step 4200, Training Loss = 1.919, Test Loss = 2.905\n",
            "Step 4300, Training Loss = 1.625, Test Loss = 3.096\n",
            "Step 4400, Training Loss = 2.343, Test Loss = 2.732\n",
            "Step 4500, Training Loss = 2.484, Test Loss = 2.516\n",
            "Step 4600, Training Loss = 2.391, Test Loss = 2.772\n",
            "TOTAL TRAINING LOSS 8979.976\n",
            "Step 0, Training Loss = 1.927, Test Loss = 2.784\n",
            "Step 1, Training Loss = 1.758, Test Loss = 2.804\n",
            "Step 100, Training Loss = 2.145, Test Loss = 3.331\n",
            "Step 200, Training Loss = 1.708, Test Loss = 3.602\n",
            "Step 300, Training Loss = 1.456, Test Loss = 2.796\n",
            "Step 400, Training Loss = 2.921, Test Loss = 2.132\n",
            "Step 500, Training Loss = 1.500, Test Loss = 2.922\n",
            "Step 600, Training Loss = 2.648, Test Loss = 3.153\n",
            "Step 700, Training Loss = 1.746, Test Loss = 2.656\n",
            "Step 800, Training Loss = 1.257, Test Loss = 3.275\n",
            "Step 900, Training Loss = 1.027, Test Loss = 3.268\n",
            "Step 1000, Training Loss = 1.838, Test Loss = 2.660\n",
            "Step 1100, Training Loss = 1.927, Test Loss = 3.022\n",
            "Step 1200, Training Loss = 2.302, Test Loss = 2.738\n",
            "Step 1300, Training Loss = 1.865, Test Loss = 2.878\n",
            "Step 1400, Training Loss = 1.455, Test Loss = 2.805\n",
            "Step 1500, Training Loss = 1.802, Test Loss = 2.449\n",
            "Step 1600, Training Loss = 1.418, Test Loss = 2.663\n",
            "Step 1700, Training Loss = 1.674, Test Loss = 2.408\n",
            "Step 1800, Training Loss = 1.845, Test Loss = 2.695\n",
            "Step 1900, Training Loss = 1.885, Test Loss = 2.644\n",
            "Step 2000, Training Loss = 1.659, Test Loss = 2.597\n",
            "Step 2100, Training Loss = 1.886, Test Loss = 2.444\n",
            "Step 2200, Training Loss = 0.891, Test Loss = 3.129\n",
            "Step 2300, Training Loss = 2.256, Test Loss = 3.084\n",
            "Step 2400, Training Loss = 2.381, Test Loss = 3.274\n",
            "Step 2500, Training Loss = 1.797, Test Loss = 2.989\n",
            "Step 2600, Training Loss = 2.053, Test Loss = 3.154\n",
            "Step 2700, Training Loss = 2.942, Test Loss = 2.818\n",
            "Step 2800, Training Loss = 1.874, Test Loss = 2.903\n",
            "Step 2900, Training Loss = 1.647, Test Loss = 2.965\n",
            "Step 3000, Training Loss = 1.542, Test Loss = 2.526\n",
            "Step 3100, Training Loss = 2.271, Test Loss = 2.754\n",
            "Step 3200, Training Loss = 1.426, Test Loss = 2.428\n",
            "Step 3300, Training Loss = 1.368, Test Loss = 2.625\n",
            "Step 3400, Training Loss = 2.045, Test Loss = 2.794\n",
            "Step 3500, Training Loss = 1.394, Test Loss = 2.777\n",
            "Step 3600, Training Loss = 1.623, Test Loss = 3.148\n",
            "Step 3700, Training Loss = 2.595, Test Loss = 2.521\n",
            "Step 3800, Training Loss = 1.329, Test Loss = 2.667\n",
            "Step 3900, Training Loss = 1.304, Test Loss = 3.009\n",
            "Step 4000, Training Loss = 1.710, Test Loss = 2.846\n",
            "Step 4100, Training Loss = 2.493, Test Loss = 2.237\n",
            "Step 4200, Training Loss = 2.366, Test Loss = 2.339\n",
            "Step 4300, Training Loss = 1.747, Test Loss = 2.611\n",
            "Step 4400, Training Loss = 1.343, Test Loss = 2.490\n",
            "Step 4500, Training Loss = 1.624, Test Loss = 2.474\n",
            "Step 4600, Training Loss = 1.444, Test Loss = 2.351\n",
            "TOTAL TRAINING LOSS 8652.702\n",
            "Step 0, Training Loss = 2.254, Test Loss = 2.918\n",
            "Step 1, Training Loss = 1.701, Test Loss = 2.932\n",
            "Step 100, Training Loss = 0.932, Test Loss = 2.396\n",
            "Step 200, Training Loss = 1.156, Test Loss = 3.006\n",
            "Step 300, Training Loss = 1.787, Test Loss = 2.833\n",
            "Step 400, Training Loss = 1.604, Test Loss = 2.932\n",
            "Step 500, Training Loss = 1.582, Test Loss = 2.327\n",
            "Step 600, Training Loss = 1.820, Test Loss = 2.612\n",
            "Step 700, Training Loss = 1.604, Test Loss = 2.807\n",
            "Step 800, Training Loss = 1.474, Test Loss = 2.674\n",
            "Step 900, Training Loss = 1.823, Test Loss = 2.954\n",
            "Step 1000, Training Loss = 2.192, Test Loss = 3.300\n",
            "Step 1100, Training Loss = 2.450, Test Loss = 2.878\n",
            "Step 1200, Training Loss = 1.149, Test Loss = 2.836\n",
            "Step 1300, Training Loss = 1.422, Test Loss = 3.015\n",
            "Step 1400, Training Loss = 2.549, Test Loss = 2.826\n",
            "Step 1500, Training Loss = 1.085, Test Loss = 3.301\n",
            "Step 1600, Training Loss = 1.401, Test Loss = 2.669\n",
            "Step 1700, Training Loss = 2.711, Test Loss = 2.618\n",
            "Step 1800, Training Loss = 1.258, Test Loss = 2.873\n",
            "Step 1900, Training Loss = 1.640, Test Loss = 2.804\n",
            "Step 2000, Training Loss = 1.681, Test Loss = 2.287\n",
            "Step 2100, Training Loss = 2.191, Test Loss = 2.596\n",
            "Step 2200, Training Loss = 1.711, Test Loss = 2.397\n",
            "Step 2300, Training Loss = 1.636, Test Loss = 2.383\n",
            "Step 2400, Training Loss = 2.045, Test Loss = 2.596\n",
            "Step 2500, Training Loss = 2.643, Test Loss = 2.332\n",
            "Step 2600, Training Loss = 1.742, Test Loss = 3.072\n",
            "Step 2700, Training Loss = 1.291, Test Loss = 2.671\n",
            "Step 2800, Training Loss = 1.899, Test Loss = 2.233\n",
            "Step 2900, Training Loss = 2.801, Test Loss = 3.210\n",
            "Step 3000, Training Loss = 1.908, Test Loss = 2.861\n",
            "Step 3100, Training Loss = 1.591, Test Loss = 2.779\n",
            "Step 3200, Training Loss = 1.259, Test Loss = 2.395\n",
            "Step 3300, Training Loss = 1.383, Test Loss = 2.460\n",
            "Step 3400, Training Loss = 1.477, Test Loss = 2.145\n",
            "Step 3500, Training Loss = 1.306, Test Loss = 2.663\n",
            "Step 3600, Training Loss = 1.687, Test Loss = 2.583\n",
            "Step 3700, Training Loss = 1.517, Test Loss = 2.931\n",
            "Step 3800, Training Loss = 0.932, Test Loss = 3.079\n",
            "Step 3900, Training Loss = 1.801, Test Loss = 2.958\n",
            "Step 4000, Training Loss = 1.135, Test Loss = 3.300\n",
            "Step 4100, Training Loss = 2.167, Test Loss = 3.001\n",
            "Step 4200, Training Loss = 1.305, Test Loss = 2.517\n",
            "Step 4300, Training Loss = 2.082, Test Loss = 2.724\n",
            "Step 4400, Training Loss = 3.108, Test Loss = 2.712\n",
            "Step 4500, Training Loss = 3.349, Test Loss = 3.172\n",
            "Step 4600, Training Loss = 1.835, Test Loss = 2.594\n",
            "TOTAL TRAINING LOSS 8380.401\n",
            "Step 0, Training Loss = 1.956, Test Loss = 2.955\n",
            "Step 1, Training Loss = 0.923, Test Loss = 2.989\n",
            "Step 100, Training Loss = 2.166, Test Loss = 2.672\n",
            "Step 200, Training Loss = 1.619, Test Loss = 2.492\n",
            "Step 300, Training Loss = 1.787, Test Loss = 2.414\n",
            "Step 400, Training Loss = 1.624, Test Loss = 2.793\n",
            "Step 500, Training Loss = 1.203, Test Loss = 2.535\n",
            "Step 600, Training Loss = 1.335, Test Loss = 2.797\n",
            "Step 700, Training Loss = 1.445, Test Loss = 2.447\n",
            "Step 800, Training Loss = 1.758, Test Loss = 2.918\n",
            "Step 900, Training Loss = 1.670, Test Loss = 3.128\n",
            "Step 1000, Training Loss = 2.122, Test Loss = 3.143\n",
            "Step 1100, Training Loss = 1.547, Test Loss = 2.535\n",
            "Step 1200, Training Loss = 2.498, Test Loss = 2.635\n",
            "Step 1300, Training Loss = 1.523, Test Loss = 2.606\n",
            "Step 1400, Training Loss = 1.659, Test Loss = 2.222\n",
            "Step 1500, Training Loss = 2.397, Test Loss = 1.958\n",
            "Step 1600, Training Loss = 1.854, Test Loss = 2.533\n",
            "Step 1700, Training Loss = 1.485, Test Loss = 2.404\n",
            "Step 1800, Training Loss = 1.488, Test Loss = 2.427\n",
            "Step 1900, Training Loss = 1.314, Test Loss = 2.826\n",
            "Step 2000, Training Loss = 1.991, Test Loss = 2.896\n",
            "Step 2100, Training Loss = 1.527, Test Loss = 2.938\n",
            "Step 2200, Training Loss = 2.683, Test Loss = 2.999\n",
            "Step 2300, Training Loss = 1.488, Test Loss = 2.915\n",
            "Step 2400, Training Loss = 1.958, Test Loss = 2.625\n",
            "Step 2500, Training Loss = 1.479, Test Loss = 2.876\n",
            "Step 2600, Training Loss = 1.530, Test Loss = 2.513\n",
            "Step 2700, Training Loss = 1.913, Test Loss = 2.758\n",
            "Step 2800, Training Loss = 1.360, Test Loss = 2.440\n",
            "Step 2900, Training Loss = 1.546, Test Loss = 2.479\n",
            "Step 3000, Training Loss = 1.465, Test Loss = 2.452\n",
            "Step 3100, Training Loss = 1.103, Test Loss = 2.962\n",
            "Step 3200, Training Loss = 1.282, Test Loss = 2.713\n",
            "Step 3300, Training Loss = 1.715, Test Loss = 2.478\n",
            "Step 3400, Training Loss = 2.170, Test Loss = 2.768\n",
            "Step 3500, Training Loss = 1.291, Test Loss = 2.617\n",
            "Step 3600, Training Loss = 1.532, Test Loss = 3.227\n",
            "Step 3700, Training Loss = 2.122, Test Loss = 2.673\n",
            "Step 3800, Training Loss = 1.563, Test Loss = 2.908\n",
            "Step 3900, Training Loss = 0.884, Test Loss = 2.708\n",
            "Step 4000, Training Loss = 1.668, Test Loss = 3.496\n",
            "Step 4100, Training Loss = 0.992, Test Loss = 2.760\n",
            "Step 4200, Training Loss = 1.325, Test Loss = 2.712\n",
            "Step 4300, Training Loss = 1.447, Test Loss = 2.472\n",
            "Step 4400, Training Loss = 1.893, Test Loss = 2.581\n",
            "Step 4500, Training Loss = 1.409, Test Loss = 2.803\n",
            "Step 4600, Training Loss = 2.177, Test Loss = 3.120\n",
            "TOTAL TRAINING LOSS 8111.777\n",
            "Step 0, Training Loss = 2.138, Test Loss = 2.669\n",
            "Step 1, Training Loss = 1.340, Test Loss = 2.673\n",
            "Step 100, Training Loss = 1.910, Test Loss = 2.384\n",
            "Step 200, Training Loss = 2.066, Test Loss = 3.008\n",
            "Step 300, Training Loss = 1.844, Test Loss = 2.676\n",
            "Step 400, Training Loss = 2.292, Test Loss = 2.848\n",
            "Step 500, Training Loss = 1.449, Test Loss = 3.163\n",
            "Step 600, Training Loss = 1.853, Test Loss = 2.602\n",
            "Step 700, Training Loss = 1.661, Test Loss = 2.702\n",
            "Step 800, Training Loss = 1.495, Test Loss = 2.839\n",
            "Step 900, Training Loss = 1.511, Test Loss = 2.587\n",
            "Step 1000, Training Loss = 1.493, Test Loss = 2.531\n",
            "Step 1100, Training Loss = 1.665, Test Loss = 2.577\n",
            "Step 1200, Training Loss = 1.926, Test Loss = 2.949\n",
            "Step 1300, Training Loss = 1.884, Test Loss = 2.845\n",
            "Step 1400, Training Loss = 1.302, Test Loss = 2.920\n",
            "Step 1500, Training Loss = 2.362, Test Loss = 2.739\n",
            "Step 1600, Training Loss = 2.786, Test Loss = 2.328\n",
            "Step 1700, Training Loss = 1.632, Test Loss = 2.552\n",
            "Step 1800, Training Loss = 1.434, Test Loss = 2.495\n",
            "Step 1900, Training Loss = 2.133, Test Loss = 2.360\n",
            "Step 2000, Training Loss = 1.605, Test Loss = 2.629\n",
            "Step 2100, Training Loss = 1.369, Test Loss = 2.422\n",
            "Step 2200, Training Loss = 0.924, Test Loss = 2.885\n",
            "Step 2300, Training Loss = 2.029, Test Loss = 2.672\n",
            "Step 2400, Training Loss = 1.172, Test Loss = 2.566\n",
            "Step 2500, Training Loss = 2.161, Test Loss = 2.638\n",
            "Step 2600, Training Loss = 1.138, Test Loss = 2.098\n",
            "Step 2700, Training Loss = 1.155, Test Loss = 2.730\n",
            "Step 2800, Training Loss = 2.235, Test Loss = 2.759\n",
            "Step 2900, Training Loss = 1.884, Test Loss = 2.929\n",
            "Step 3000, Training Loss = 1.588, Test Loss = 2.645\n",
            "Step 3100, Training Loss = 2.093, Test Loss = 2.733\n",
            "Step 3200, Training Loss = 1.451, Test Loss = 2.490\n",
            "Step 3300, Training Loss = 2.171, Test Loss = 2.728\n",
            "Step 3400, Training Loss = 1.565, Test Loss = 2.704\n",
            "Step 3500, Training Loss = 1.210, Test Loss = 2.789\n",
            "Step 3600, Training Loss = 1.883, Test Loss = 2.281\n",
            "Step 3700, Training Loss = 1.406, Test Loss = 2.486\n",
            "Step 3800, Training Loss = 2.159, Test Loss = 2.261\n",
            "Step 3900, Training Loss = 1.705, Test Loss = 2.168\n",
            "Step 4000, Training Loss = 1.326, Test Loss = 2.886\n",
            "Step 4100, Training Loss = 1.407, Test Loss = 2.307\n",
            "Step 4200, Training Loss = 2.131, Test Loss = 2.406\n",
            "Step 4300, Training Loss = 1.793, Test Loss = 2.715\n",
            "Step 4400, Training Loss = 2.826, Test Loss = 2.288\n",
            "Step 4500, Training Loss = 1.569, Test Loss = 2.481\n",
            "Step 4600, Training Loss = 1.517, Test Loss = 2.865\n",
            "TOTAL TRAINING LOSS 7885.529\n",
            "Step 0, Training Loss = 1.034, Test Loss = 3.134\n",
            "Step 1, Training Loss = 1.788, Test Loss = 3.156\n",
            "Step 100, Training Loss = 2.339, Test Loss = 3.314\n",
            "Step 200, Training Loss = 1.763, Test Loss = 2.793\n",
            "Step 300, Training Loss = 1.185, Test Loss = 2.870\n",
            "Step 400, Training Loss = 2.022, Test Loss = 2.824\n",
            "Step 500, Training Loss = 1.181, Test Loss = 2.484\n",
            "Step 600, Training Loss = 1.645, Test Loss = 2.470\n",
            "Step 700, Training Loss = 1.811, Test Loss = 2.274\n",
            "Step 800, Training Loss = 1.442, Test Loss = 2.401\n",
            "Step 900, Training Loss = 1.956, Test Loss = 2.754\n",
            "Step 1000, Training Loss = 1.515, Test Loss = 2.195\n",
            "Step 1100, Training Loss = 1.866, Test Loss = 2.362\n",
            "Step 1200, Training Loss = 1.191, Test Loss = 2.446\n",
            "Step 1300, Training Loss = 1.173, Test Loss = 2.587\n",
            "Step 1400, Training Loss = 1.604, Test Loss = 2.334\n",
            "Step 1500, Training Loss = 1.929, Test Loss = 2.438\n",
            "Step 1600, Training Loss = 1.584, Test Loss = 2.939\n",
            "Step 1700, Training Loss = 1.431, Test Loss = 2.853\n",
            "Step 1800, Training Loss = 1.735, Test Loss = 2.609\n",
            "Step 1900, Training Loss = 1.990, Test Loss = 2.570\n",
            "Step 2000, Training Loss = 1.385, Test Loss = 2.116\n",
            "Step 2100, Training Loss = 2.110, Test Loss = 2.019\n",
            "Step 2200, Training Loss = 1.943, Test Loss = 2.540\n",
            "Step 2300, Training Loss = 2.188, Test Loss = 2.409\n",
            "Step 2400, Training Loss = 1.281, Test Loss = 2.350\n",
            "Step 2500, Training Loss = 1.631, Test Loss = 2.709\n",
            "Step 2600, Training Loss = 1.841, Test Loss = 2.448\n",
            "Step 2700, Training Loss = 1.644, Test Loss = 2.942\n",
            "Step 2800, Training Loss = 1.585, Test Loss = 2.394\n",
            "Step 2900, Training Loss = 1.799, Test Loss = 2.523\n",
            "Step 3000, Training Loss = 2.110, Test Loss = 2.523\n",
            "Step 3100, Training Loss = 1.441, Test Loss = 2.432\n",
            "Step 3200, Training Loss = 1.501, Test Loss = 2.782\n",
            "Step 3300, Training Loss = 1.890, Test Loss = 2.718\n",
            "Step 3400, Training Loss = 2.352, Test Loss = 3.047\n",
            "Step 3500, Training Loss = 1.551, Test Loss = 3.039\n",
            "Step 3600, Training Loss = 1.447, Test Loss = 2.561\n",
            "Step 3700, Training Loss = 1.560, Test Loss = 2.312\n",
            "Step 3800, Training Loss = 2.002, Test Loss = 2.273\n",
            "Step 3900, Training Loss = 1.419, Test Loss = 2.847\n",
            "Step 4000, Training Loss = 1.883, Test Loss = 2.760\n",
            "Step 4100, Training Loss = 1.726, Test Loss = 2.909\n",
            "Step 4200, Training Loss = 1.991, Test Loss = 2.892\n",
            "Step 4300, Training Loss = 1.438, Test Loss = 2.939\n",
            "Step 4400, Training Loss = 1.261, Test Loss = 2.711\n",
            "Step 4500, Training Loss = 1.861, Test Loss = 2.446\n",
            "Step 4600, Training Loss = 1.313, Test Loss = 2.445\n",
            "TOTAL TRAINING LOSS 7692.829\n",
            "Step 0, Training Loss = 1.001, Test Loss = 2.474\n",
            "Step 1, Training Loss = 1.741, Test Loss = 2.470\n",
            "Step 100, Training Loss = 1.507, Test Loss = 2.535\n",
            "Step 200, Training Loss = 1.292, Test Loss = 2.713\n",
            "Step 300, Training Loss = 1.255, Test Loss = 2.860\n",
            "Step 400, Training Loss = 1.679, Test Loss = 2.871\n",
            "Step 500, Training Loss = 1.867, Test Loss = 2.745\n",
            "Step 600, Training Loss = 1.156, Test Loss = 2.957\n",
            "Step 700, Training Loss = 2.377, Test Loss = 3.136\n",
            "Step 800, Training Loss = 1.558, Test Loss = 2.427\n",
            "Step 900, Training Loss = 1.264, Test Loss = 2.636\n",
            "Step 1000, Training Loss = 0.724, Test Loss = 2.380\n",
            "Step 1100, Training Loss = 2.528, Test Loss = 2.722\n",
            "Step 1200, Training Loss = 0.925, Test Loss = 2.527\n",
            "Step 1300, Training Loss = 2.227, Test Loss = 3.059\n",
            "Step 1400, Training Loss = 1.767, Test Loss = 3.023\n",
            "Step 1500, Training Loss = 1.499, Test Loss = 2.812\n",
            "Step 1600, Training Loss = 2.487, Test Loss = 3.101\n",
            "Step 1700, Training Loss = 2.477, Test Loss = 2.238\n",
            "Step 1800, Training Loss = 1.801, Test Loss = 2.304\n",
            "Step 1900, Training Loss = 1.879, Test Loss = 2.454\n",
            "Step 2000, Training Loss = 3.296, Test Loss = 2.244\n",
            "Step 2100, Training Loss = 1.578, Test Loss = 2.443\n",
            "Step 2200, Training Loss = 1.146, Test Loss = 2.216\n",
            "Step 2300, Training Loss = 1.186, Test Loss = 2.500\n",
            "Step 2400, Training Loss = 1.439, Test Loss = 2.532\n",
            "Step 2500, Training Loss = 1.013, Test Loss = 2.528\n",
            "Step 2600, Training Loss = 1.318, Test Loss = 2.686\n",
            "Step 2700, Training Loss = 0.964, Test Loss = 2.536\n",
            "Step 2800, Training Loss = 1.391, Test Loss = 2.153\n",
            "Step 2900, Training Loss = 1.392, Test Loss = 2.498\n",
            "Step 3000, Training Loss = 1.691, Test Loss = 2.650\n",
            "Step 3100, Training Loss = 4.351, Test Loss = 2.360\n",
            "Step 3200, Training Loss = 1.733, Test Loss = 2.639\n",
            "Step 3300, Training Loss = 1.198, Test Loss = 2.599\n",
            "Step 3400, Training Loss = 1.596, Test Loss = 2.272\n",
            "Step 3500, Training Loss = 1.394, Test Loss = 2.155\n",
            "Step 3600, Training Loss = 1.233, Test Loss = 2.427\n",
            "Step 3700, Training Loss = 1.078, Test Loss = 2.177\n",
            "Step 3800, Training Loss = 1.158, Test Loss = 2.719\n",
            "Step 3900, Training Loss = 1.155, Test Loss = 3.033\n",
            "Step 4000, Training Loss = 1.923, Test Loss = 2.619\n",
            "Step 4100, Training Loss = 1.032, Test Loss = 2.380\n",
            "Step 4200, Training Loss = 1.247, Test Loss = 2.560\n",
            "Step 4300, Training Loss = 1.527, Test Loss = 2.408\n",
            "Step 4400, Training Loss = 1.503, Test Loss = 2.507\n",
            "Step 4500, Training Loss = 2.043, Test Loss = 2.446\n",
            "Step 4600, Training Loss = 0.812, Test Loss = 2.559\n",
            "TOTAL TRAINING LOSS 7498.403\n",
            "Step 0, Training Loss = 1.231, Test Loss = 2.549\n",
            "Step 1, Training Loss = 1.818, Test Loss = 2.508\n",
            "Step 100, Training Loss = 1.718, Test Loss = 2.062\n",
            "Step 200, Training Loss = 1.311, Test Loss = 2.413\n",
            "Step 300, Training Loss = 1.562, Test Loss = 2.695\n",
            "Step 400, Training Loss = 2.113, Test Loss = 2.734\n",
            "Step 500, Training Loss = 1.707, Test Loss = 2.566\n",
            "Step 600, Training Loss = 1.737, Test Loss = 2.558\n",
            "Step 700, Training Loss = 1.488, Test Loss = 2.838\n",
            "Step 800, Training Loss = 2.158, Test Loss = 2.330\n",
            "Step 900, Training Loss = 1.783, Test Loss = 3.026\n",
            "Step 1000, Training Loss = 1.134, Test Loss = 2.638\n",
            "Step 1100, Training Loss = 1.185, Test Loss = 2.547\n",
            "Step 1200, Training Loss = 1.617, Test Loss = 2.265\n",
            "Step 1300, Training Loss = 1.371, Test Loss = 2.309\n",
            "Step 1400, Training Loss = 1.275, Test Loss = 2.276\n",
            "Step 1500, Training Loss = 1.787, Test Loss = 2.994\n",
            "Step 1600, Training Loss = 1.803, Test Loss = 2.823\n",
            "Step 1700, Training Loss = 2.062, Test Loss = 2.672\n",
            "Step 1800, Training Loss = 2.064, Test Loss = 2.682\n",
            "Step 1900, Training Loss = 2.088, Test Loss = 2.543\n",
            "Step 2000, Training Loss = 0.684, Test Loss = 2.579\n",
            "Step 2100, Training Loss = 1.134, Test Loss = 2.702\n",
            "Step 2200, Training Loss = 2.513, Test Loss = 2.450\n",
            "Step 2300, Training Loss = 1.576, Test Loss = 2.103\n",
            "Step 2400, Training Loss = 1.745, Test Loss = 2.071\n",
            "Step 2500, Training Loss = 1.463, Test Loss = 2.437\n",
            "Step 2600, Training Loss = 1.799, Test Loss = 2.450\n",
            "Step 2700, Training Loss = 2.138, Test Loss = 2.263\n",
            "Step 2800, Training Loss = 1.153, Test Loss = 2.804\n",
            "Step 2900, Training Loss = 1.410, Test Loss = 2.536\n",
            "Step 3000, Training Loss = 1.253, Test Loss = 2.917\n",
            "Step 3100, Training Loss = 1.721, Test Loss = 2.585\n",
            "Step 3200, Training Loss = 1.152, Test Loss = 2.835\n",
            "Step 3300, Training Loss = 1.812, Test Loss = 2.033\n",
            "Step 3400, Training Loss = 1.319, Test Loss = 2.205\n",
            "Step 3500, Training Loss = 1.384, Test Loss = 2.239\n",
            "Step 3600, Training Loss = 1.530, Test Loss = 2.568\n",
            "Step 3700, Training Loss = 1.413, Test Loss = 2.066\n",
            "Step 3800, Training Loss = 1.618, Test Loss = 2.495\n",
            "Step 3900, Training Loss = 1.602, Test Loss = 2.576\n",
            "Step 4000, Training Loss = 1.277, Test Loss = 2.208\n",
            "Step 4100, Training Loss = 1.587, Test Loss = 2.658\n",
            "Step 4200, Training Loss = 1.887, Test Loss = 2.567\n",
            "Step 4300, Training Loss = 1.161, Test Loss = 2.384\n",
            "Step 4400, Training Loss = 1.202, Test Loss = 2.395\n",
            "Step 4500, Training Loss = 1.311, Test Loss = 2.654\n",
            "Step 4600, Training Loss = 1.303, Test Loss = 2.876\n",
            "TOTAL TRAINING LOSS 7329.509\n",
            "Step 0, Training Loss = 1.292, Test Loss = 2.545\n",
            "Step 1, Training Loss = 1.482, Test Loss = 2.553\n",
            "Step 100, Training Loss = 1.636, Test Loss = 3.053\n",
            "Step 200, Training Loss = 1.509, Test Loss = 2.802\n",
            "Step 300, Training Loss = 1.388, Test Loss = 2.844\n",
            "Step 400, Training Loss = 0.718, Test Loss = 2.645\n",
            "Step 500, Training Loss = 1.582, Test Loss = 2.557\n",
            "Step 600, Training Loss = 1.464, Test Loss = 2.739\n",
            "Step 700, Training Loss = 0.991, Test Loss = 2.806\n",
            "Step 800, Training Loss = 1.292, Test Loss = 2.483\n",
            "Step 900, Training Loss = 1.009, Test Loss = 2.518\n",
            "Step 1000, Training Loss = 0.917, Test Loss = 2.296\n",
            "Step 1100, Training Loss = 1.114, Test Loss = 2.147\n",
            "Step 1200, Training Loss = 1.241, Test Loss = 2.362\n",
            "Step 1300, Training Loss = 0.987, Test Loss = 2.478\n",
            "Step 1400, Training Loss = 1.503, Test Loss = 2.349\n",
            "Step 1500, Training Loss = 1.459, Test Loss = 2.715\n",
            "Step 1600, Training Loss = 1.137, Test Loss = 2.371\n",
            "Step 1700, Training Loss = 1.586, Test Loss = 2.525\n",
            "Step 1800, Training Loss = 1.246, Test Loss = 2.549\n",
            "Step 1900, Training Loss = 1.421, Test Loss = 2.558\n",
            "Step 2000, Training Loss = 1.676, Test Loss = 2.317\n",
            "Step 2100, Training Loss = 1.412, Test Loss = 2.167\n",
            "Step 2200, Training Loss = 1.503, Test Loss = 2.641\n",
            "Step 2300, Training Loss = 1.606, Test Loss = 2.227\n",
            "Step 2400, Training Loss = 1.280, Test Loss = 2.340\n",
            "Step 2500, Training Loss = 1.091, Test Loss = 2.065\n",
            "Step 2600, Training Loss = 1.415, Test Loss = 2.479\n",
            "Step 2700, Training Loss = 1.559, Test Loss = 2.144\n",
            "Step 2800, Training Loss = 1.832, Test Loss = 1.966\n",
            "Step 2900, Training Loss = 1.244, Test Loss = 2.439\n",
            "Step 3000, Training Loss = 1.996, Test Loss = 2.398\n",
            "Step 3100, Training Loss = 1.658, Test Loss = 2.428\n",
            "Step 3200, Training Loss = 1.172, Test Loss = 2.770\n",
            "Step 3300, Training Loss = 2.806, Test Loss = 2.471\n",
            "Step 3400, Training Loss = 1.522, Test Loss = 2.679\n",
            "Step 3500, Training Loss = 1.357, Test Loss = 2.607\n",
            "Step 3600, Training Loss = 1.221, Test Loss = 2.598\n",
            "Step 3700, Training Loss = 1.867, Test Loss = 2.337\n",
            "Step 3800, Training Loss = 1.130, Test Loss = 2.544\n",
            "Step 3900, Training Loss = 2.019, Test Loss = 2.167\n",
            "Step 4000, Training Loss = 1.753, Test Loss = 2.575\n",
            "Step 4100, Training Loss = 1.153, Test Loss = 2.406\n",
            "Step 4200, Training Loss = 1.388, Test Loss = 2.618\n",
            "Step 4300, Training Loss = 1.204, Test Loss = 2.649\n",
            "Step 4400, Training Loss = 2.056, Test Loss = 2.340\n",
            "Step 4500, Training Loss = 2.214, Test Loss = 2.639\n",
            "Step 4600, Training Loss = 2.302, Test Loss = 2.460\n",
            "TOTAL TRAINING LOSS 7171.498\n",
            "Step 0, Training Loss = 0.915, Test Loss = 2.388\n",
            "Step 1, Training Loss = 1.366, Test Loss = 2.396\n",
            "Step 100, Training Loss = 1.248, Test Loss = 2.672\n",
            "Step 200, Training Loss = 2.023, Test Loss = 2.709\n",
            "Step 300, Training Loss = 1.232, Test Loss = 2.471\n",
            "Step 400, Training Loss = 1.770, Test Loss = 2.568\n",
            "Step 500, Training Loss = 1.258, Test Loss = 2.354\n",
            "Step 600, Training Loss = 1.334, Test Loss = 2.415\n",
            "Step 700, Training Loss = 2.358, Test Loss = 2.453\n",
            "Step 800, Training Loss = 1.816, Test Loss = 2.338\n",
            "Step 900, Training Loss = 0.679, Test Loss = 2.404\n",
            "Step 1000, Training Loss = 1.042, Test Loss = 2.299\n",
            "Step 1100, Training Loss = 1.307, Test Loss = 2.296\n",
            "Step 1200, Training Loss = 1.234, Test Loss = 2.649\n",
            "Step 1300, Training Loss = 1.478, Test Loss = 2.361\n",
            "Step 1400, Training Loss = 2.126, Test Loss = 2.623\n",
            "Step 1500, Training Loss = 1.458, Test Loss = 2.907\n",
            "Step 1600, Training Loss = 2.685, Test Loss = 2.381\n",
            "Step 1700, Training Loss = 2.007, Test Loss = 2.582\n",
            "Step 1800, Training Loss = 1.409, Test Loss = 2.433\n",
            "Step 1900, Training Loss = 1.238, Test Loss = 1.959\n",
            "Step 2000, Training Loss = 1.564, Test Loss = 2.315\n",
            "Step 2100, Training Loss = 1.469, Test Loss = 2.435\n",
            "Step 2200, Training Loss = 1.469, Test Loss = 2.593\n",
            "Step 2300, Training Loss = 1.077, Test Loss = 2.817\n",
            "Step 2400, Training Loss = 1.605, Test Loss = 2.662\n",
            "Step 2500, Training Loss = 1.420, Test Loss = 2.614\n",
            "Step 2600, Training Loss = 1.806, Test Loss = 2.413\n",
            "Step 2700, Training Loss = 1.547, Test Loss = 2.769\n",
            "Step 2800, Training Loss = 1.691, Test Loss = 3.038\n",
            "Step 2900, Training Loss = 1.630, Test Loss = 2.714\n",
            "Step 3000, Training Loss = 1.444, Test Loss = 2.381\n",
            "Step 3100, Training Loss = 1.301, Test Loss = 2.359\n",
            "Step 3200, Training Loss = 1.597, Test Loss = 2.564\n",
            "Step 3300, Training Loss = 1.416, Test Loss = 2.119\n",
            "Step 3400, Training Loss = 1.426, Test Loss = 2.269\n",
            "Step 3500, Training Loss = 1.355, Test Loss = 2.326\n",
            "Step 3600, Training Loss = 1.251, Test Loss = 2.636\n",
            "Step 3700, Training Loss = 1.688, Test Loss = 2.374\n",
            "Step 3800, Training Loss = 1.122, Test Loss = 2.455\n",
            "Step 3900, Training Loss = 1.604, Test Loss = 2.443\n",
            "Step 4000, Training Loss = 1.605, Test Loss = 2.779\n",
            "Step 4100, Training Loss = 1.033, Test Loss = 2.783\n",
            "Step 4200, Training Loss = 2.177, Test Loss = 2.227\n",
            "Step 4300, Training Loss = 1.604, Test Loss = 2.435\n",
            "Step 4400, Training Loss = 1.653, Test Loss = 2.373\n",
            "Step 4500, Training Loss = 1.570, Test Loss = 2.446\n",
            "Step 4600, Training Loss = 0.733, Test Loss = 2.938\n",
            "TOTAL TRAINING LOSS 7016.144\n",
            "Step 0, Training Loss = 1.133, Test Loss = 2.940\n",
            "Step 1, Training Loss = 1.376, Test Loss = 2.926\n",
            "Step 100, Training Loss = 1.101, Test Loss = 2.256\n",
            "Step 200, Training Loss = 1.111, Test Loss = 2.504\n",
            "Step 300, Training Loss = 1.409, Test Loss = 2.920\n",
            "Step 400, Training Loss = 1.692, Test Loss = 2.670\n",
            "Step 500, Training Loss = 1.448, Test Loss = 2.241\n",
            "Step 600, Training Loss = 1.053, Test Loss = 2.555\n",
            "Step 700, Training Loss = 1.552, Test Loss = 2.341\n",
            "Step 800, Training Loss = 0.995, Test Loss = 2.503\n",
            "Step 900, Training Loss = 1.463, Test Loss = 2.406\n",
            "Step 1000, Training Loss = 1.754, Test Loss = 2.632\n",
            "Step 1100, Training Loss = 1.759, Test Loss = 2.174\n",
            "Step 1200, Training Loss = 1.768, Test Loss = 2.392\n",
            "Step 1300, Training Loss = 1.672, Test Loss = 2.681\n",
            "Step 1400, Training Loss = 1.263, Test Loss = 2.577\n",
            "Step 1500, Training Loss = 1.872, Test Loss = 2.587\n",
            "Step 1600, Training Loss = 2.691, Test Loss = 2.583\n",
            "Step 1700, Training Loss = 1.945, Test Loss = 2.399\n",
            "Step 1800, Training Loss = 2.160, Test Loss = 2.926\n",
            "Step 1900, Training Loss = 1.620, Test Loss = 2.522\n",
            "Step 2000, Training Loss = 1.108, Test Loss = 2.425\n",
            "Step 2100, Training Loss = 1.421, Test Loss = 2.250\n",
            "Step 2200, Training Loss = 1.462, Test Loss = 2.444\n",
            "Step 2300, Training Loss = 0.979, Test Loss = 2.318\n",
            "Step 2400, Training Loss = 1.676, Test Loss = 2.534\n",
            "Step 2500, Training Loss = 1.760, Test Loss = 2.497\n",
            "Step 2600, Training Loss = 1.247, Test Loss = 2.419\n",
            "Step 2700, Training Loss = 2.124, Test Loss = 2.450\n",
            "Step 2800, Training Loss = 1.352, Test Loss = 2.425\n",
            "Step 2900, Training Loss = 1.706, Test Loss = 2.453\n",
            "Step 3000, Training Loss = 0.855, Test Loss = 2.739\n",
            "Step 3100, Training Loss = 1.407, Test Loss = 2.319\n",
            "Step 3200, Training Loss = 1.540, Test Loss = 2.493\n",
            "Step 3300, Training Loss = 2.189, Test Loss = 2.679\n",
            "Step 3400, Training Loss = 1.137, Test Loss = 2.442\n",
            "Step 3500, Training Loss = 1.870, Test Loss = 2.871\n",
            "Step 3600, Training Loss = 1.538, Test Loss = 2.461\n",
            "Step 3700, Training Loss = 1.593, Test Loss = 2.330\n",
            "Step 3800, Training Loss = 1.192, Test Loss = 2.784\n",
            "Step 3900, Training Loss = 0.710, Test Loss = 2.487\n",
            "Step 4000, Training Loss = 1.849, Test Loss = 2.201\n",
            "Step 4100, Training Loss = 1.692, Test Loss = 2.237\n",
            "Step 4200, Training Loss = 1.512, Test Loss = 2.217\n",
            "Step 4300, Training Loss = 2.198, Test Loss = 2.436\n",
            "Step 4400, Training Loss = 1.338, Test Loss = 2.414\n",
            "Step 4500, Training Loss = 1.507, Test Loss = 2.417\n",
            "Step 4600, Training Loss = 0.949, Test Loss = 2.343\n",
            "TOTAL TRAINING LOSS 6890.279\n",
            "Step 0, Training Loss = 1.410, Test Loss = 2.566\n",
            "Step 1, Training Loss = 1.846, Test Loss = 2.523\n",
            "Step 100, Training Loss = 1.549, Test Loss = 2.596\n",
            "Step 200, Training Loss = 2.213, Test Loss = 2.632\n",
            "Step 300, Training Loss = 1.404, Test Loss = 2.526\n",
            "Step 400, Training Loss = 1.227, Test Loss = 2.640\n",
            "Step 500, Training Loss = 1.931, Test Loss = 2.247\n",
            "Step 600, Training Loss = 1.119, Test Loss = 2.126\n",
            "Step 700, Training Loss = 1.092, Test Loss = 1.991\n",
            "Step 800, Training Loss = 2.290, Test Loss = 2.459\n",
            "Step 900, Training Loss = 2.133, Test Loss = 2.471\n",
            "Step 1000, Training Loss = 1.377, Test Loss = 2.411\n",
            "Step 1100, Training Loss = 1.105, Test Loss = 2.510\n",
            "Step 1200, Training Loss = 2.524, Test Loss = 2.263\n",
            "Step 1300, Training Loss = 1.260, Test Loss = 2.624\n",
            "Step 1400, Training Loss = 1.726, Test Loss = 2.404\n",
            "Step 1500, Training Loss = 1.506, Test Loss = 2.639\n",
            "Step 1600, Training Loss = 1.615, Test Loss = 2.988\n",
            "Step 1700, Training Loss = 0.992, Test Loss = 2.468\n",
            "Step 1800, Training Loss = 1.013, Test Loss = 2.280\n",
            "Step 1900, Training Loss = 2.207, Test Loss = 2.391\n",
            "Step 2000, Training Loss = 1.233, Test Loss = 2.662\n",
            "Step 2100, Training Loss = 1.488, Test Loss = 2.296\n",
            "Step 2200, Training Loss = 1.463, Test Loss = 2.381\n",
            "Step 2300, Training Loss = 1.437, Test Loss = 2.321\n",
            "Step 2400, Training Loss = 1.531, Test Loss = 2.399\n",
            "Step 2500, Training Loss = 1.473, Test Loss = 2.753\n",
            "Step 2600, Training Loss = 1.402, Test Loss = 2.683\n",
            "Step 2700, Training Loss = 1.054, Test Loss = 2.479\n",
            "Step 2800, Training Loss = 1.263, Test Loss = 2.656\n",
            "Step 2900, Training Loss = 1.353, Test Loss = 2.487\n",
            "Step 3000, Training Loss = 1.678, Test Loss = 2.837\n",
            "Step 3100, Training Loss = 1.159, Test Loss = 2.318\n",
            "Step 3200, Training Loss = 1.134, Test Loss = 2.369\n",
            "Step 3300, Training Loss = 1.469, Test Loss = 2.229\n",
            "Step 3400, Training Loss = 1.438, Test Loss = 2.365\n",
            "Step 3500, Training Loss = 1.825, Test Loss = 2.295\n",
            "Step 3600, Training Loss = 1.329, Test Loss = 2.323\n",
            "Step 3700, Training Loss = 2.036, Test Loss = 2.106\n",
            "Step 3800, Training Loss = 1.520, Test Loss = 2.310\n",
            "Step 3900, Training Loss = 1.193, Test Loss = 2.511\n",
            "Step 4000, Training Loss = 1.342, Test Loss = 2.422\n",
            "Step 4100, Training Loss = 1.226, Test Loss = 2.343\n",
            "Step 4200, Training Loss = 1.055, Test Loss = 2.593\n",
            "Step 4300, Training Loss = 1.931, Test Loss = 2.437\n",
            "Step 4400, Training Loss = 1.765, Test Loss = 2.546\n",
            "Step 4500, Training Loss = 1.282, Test Loss = 2.418\n",
            "Step 4600, Training Loss = 1.750, Test Loss = 2.270\n",
            "TOTAL TRAINING LOSS 6755.651\n",
            "Step 0, Training Loss = 1.138, Test Loss = 2.643\n",
            "Step 1, Training Loss = 1.244, Test Loss = 2.648\n",
            "Step 100, Training Loss = 1.017, Test Loss = 2.446\n",
            "Step 200, Training Loss = 1.122, Test Loss = 2.266\n",
            "Step 300, Training Loss = 1.293, Test Loss = 2.389\n",
            "Step 400, Training Loss = 1.674, Test Loss = 2.873\n",
            "Step 500, Training Loss = 1.441, Test Loss = 2.755\n",
            "Step 600, Training Loss = 1.247, Test Loss = 2.585\n",
            "Step 700, Training Loss = 1.201, Test Loss = 2.639\n",
            "Step 800, Training Loss = 1.065, Test Loss = 2.351\n",
            "Step 900, Training Loss = 1.318, Test Loss = 2.716\n",
            "Step 1000, Training Loss = 2.095, Test Loss = 2.440\n",
            "Step 1100, Training Loss = 1.433, Test Loss = 2.293\n",
            "Step 1200, Training Loss = 1.391, Test Loss = 2.593\n",
            "Step 1300, Training Loss = 1.185, Test Loss = 2.510\n",
            "Step 1400, Training Loss = 1.348, Test Loss = 2.547\n",
            "Step 1500, Training Loss = 1.370, Test Loss = 2.196\n",
            "Step 1600, Training Loss = 1.132, Test Loss = 2.648\n",
            "Step 1700, Training Loss = 2.136, Test Loss = 2.190\n",
            "Step 1800, Training Loss = 0.994, Test Loss = 2.361\n",
            "Step 1900, Training Loss = 1.487, Test Loss = 2.384\n",
            "Step 2000, Training Loss = 1.484, Test Loss = 2.250\n",
            "Step 2100, Training Loss = 2.003, Test Loss = 2.148\n",
            "Step 2200, Training Loss = 0.959, Test Loss = 1.986\n",
            "Step 2300, Training Loss = 1.472, Test Loss = 2.551\n",
            "Step 2400, Training Loss = 2.421, Test Loss = 2.595\n",
            "Step 2500, Training Loss = 1.146, Test Loss = 2.563\n",
            "Step 2600, Training Loss = 2.306, Test Loss = 2.208\n",
            "Step 2700, Training Loss = 0.962, Test Loss = 2.260\n",
            "Step 2800, Training Loss = 1.874, Test Loss = 2.671\n",
            "Step 2900, Training Loss = 0.961, Test Loss = 2.651\n",
            "Step 3000, Training Loss = 1.412, Test Loss = 2.246\n",
            "Step 3100, Training Loss = 1.718, Test Loss = 2.330\n",
            "Step 3200, Training Loss = 1.625, Test Loss = 2.631\n",
            "Step 3300, Training Loss = 1.224, Test Loss = 2.447\n",
            "Step 3400, Training Loss = 1.421, Test Loss = 2.464\n",
            "Step 3500, Training Loss = 1.385, Test Loss = 2.789\n",
            "Step 3600, Training Loss = 1.956, Test Loss = 2.745\n",
            "Step 3700, Training Loss = 1.008, Test Loss = 2.431\n",
            "Step 3800, Training Loss = 1.463, Test Loss = 2.195\n",
            "Step 3900, Training Loss = 1.245, Test Loss = 2.094\n",
            "Step 4000, Training Loss = 0.999, Test Loss = 2.296\n",
            "Step 4100, Training Loss = 2.109, Test Loss = 2.637\n",
            "Step 4200, Training Loss = 2.231, Test Loss = 2.353\n",
            "Step 4300, Training Loss = 1.398, Test Loss = 2.290\n",
            "Step 4400, Training Loss = 1.280, Test Loss = 2.230\n",
            "Step 4500, Training Loss = 1.087, Test Loss = 2.511\n",
            "Step 4600, Training Loss = 1.459, Test Loss = 2.602\n",
            "TOTAL TRAINING LOSS 6631.891\n",
            "Step 0, Training Loss = 0.802, Test Loss = 2.410\n",
            "Step 1, Training Loss = 1.277, Test Loss = 2.374\n",
            "Step 100, Training Loss = 1.187, Test Loss = 2.394\n",
            "Step 200, Training Loss = 0.940, Test Loss = 2.585\n",
            "Step 300, Training Loss = 1.481, Test Loss = 2.643\n",
            "Step 400, Training Loss = 1.419, Test Loss = 2.780\n",
            "Step 500, Training Loss = 1.365, Test Loss = 2.637\n",
            "Step 600, Training Loss = 1.826, Test Loss = 2.349\n",
            "Step 700, Training Loss = 1.109, Test Loss = 2.113\n",
            "Step 800, Training Loss = 0.954, Test Loss = 2.286\n",
            "Step 900, Training Loss = 2.878, Test Loss = 2.455\n",
            "Step 1000, Training Loss = 1.475, Test Loss = 2.412\n",
            "Step 1100, Training Loss = 1.535, Test Loss = 2.396\n",
            "Step 1200, Training Loss = 1.843, Test Loss = 1.923\n",
            "Step 1300, Training Loss = 1.705, Test Loss = 2.691\n",
            "Step 1400, Training Loss = 1.364, Test Loss = 2.505\n",
            "Step 1500, Training Loss = 1.867, Test Loss = 2.607\n",
            "Step 1600, Training Loss = 1.395, Test Loss = 2.343\n",
            "Step 1700, Training Loss = 1.739, Test Loss = 2.363\n",
            "Step 1800, Training Loss = 1.616, Test Loss = 2.429\n",
            "Step 1900, Training Loss = 1.033, Test Loss = 2.034\n",
            "Step 2000, Training Loss = 1.788, Test Loss = 2.269\n",
            "Step 2100, Training Loss = 2.207, Test Loss = 2.342\n",
            "Step 2200, Training Loss = 1.645, Test Loss = 2.391\n",
            "Step 2300, Training Loss = 1.176, Test Loss = 2.292\n",
            "Step 2400, Training Loss = 1.057, Test Loss = 2.364\n",
            "Step 2500, Training Loss = 0.952, Test Loss = 2.370\n",
            "Step 2600, Training Loss = 0.996, Test Loss = 2.367\n",
            "Step 2700, Training Loss = 1.021, Test Loss = 2.517\n",
            "Step 2800, Training Loss = 0.661, Test Loss = 2.297\n",
            "Step 2900, Training Loss = 1.641, Test Loss = 2.784\n",
            "Step 3000, Training Loss = 1.819, Test Loss = 2.341\n",
            "Step 3100, Training Loss = 1.901, Test Loss = 2.427\n",
            "Step 3200, Training Loss = 1.663, Test Loss = 2.362\n",
            "Step 3300, Training Loss = 1.713, Test Loss = 2.413\n",
            "Step 3400, Training Loss = 0.865, Test Loss = 2.380\n",
            "Step 3500, Training Loss = 1.594, Test Loss = 2.605\n",
            "Step 3600, Training Loss = 1.893, Test Loss = 2.389\n",
            "Step 3700, Training Loss = 1.807, Test Loss = 2.261\n",
            "Step 3800, Training Loss = 1.495, Test Loss = 2.267\n",
            "Step 3900, Training Loss = 1.720, Test Loss = 2.156\n",
            "Step 4000, Training Loss = 1.280, Test Loss = 2.219\n",
            "Step 4100, Training Loss = 1.263, Test Loss = 2.641\n",
            "Step 4200, Training Loss = 1.344, Test Loss = 2.440\n",
            "Step 4300, Training Loss = 1.342, Test Loss = 2.779\n",
            "Step 4400, Training Loss = 1.583, Test Loss = 2.108\n",
            "Step 4500, Training Loss = 1.387, Test Loss = 2.255\n",
            "Step 4600, Training Loss = 1.323, Test Loss = 2.272\n",
            "TOTAL TRAINING LOSS 6515.200\n",
            "Step 0, Training Loss = 0.964, Test Loss = 2.435\n",
            "Step 1, Training Loss = 1.164, Test Loss = 2.479\n",
            "Step 100, Training Loss = 1.276, Test Loss = 2.275\n",
            "Step 200, Training Loss = 1.314, Test Loss = 2.517\n",
            "Step 300, Training Loss = 1.624, Test Loss = 2.319\n",
            "Step 400, Training Loss = 1.167, Test Loss = 2.284\n",
            "Step 500, Training Loss = 1.275, Test Loss = 2.697\n",
            "Step 600, Training Loss = 1.733, Test Loss = 2.746\n",
            "Step 700, Training Loss = 1.163, Test Loss = 2.412\n",
            "Step 800, Training Loss = 1.209, Test Loss = 2.317\n",
            "Step 900, Training Loss = 3.091, Test Loss = 2.251\n",
            "Step 1000, Training Loss = 1.601, Test Loss = 2.354\n",
            "Step 1100, Training Loss = 1.243, Test Loss = 2.375\n",
            "Step 1200, Training Loss = 1.421, Test Loss = 2.167\n",
            "Step 1300, Training Loss = 1.030, Test Loss = 2.208\n",
            "Step 1400, Training Loss = 1.040, Test Loss = 2.422\n",
            "Step 1500, Training Loss = 1.298, Test Loss = 2.361\n",
            "Step 1600, Training Loss = 1.588, Test Loss = 2.622\n",
            "Step 1700, Training Loss = 1.055, Test Loss = 2.460\n",
            "Step 1800, Training Loss = 1.645, Test Loss = 2.174\n",
            "Step 1900, Training Loss = 1.310, Test Loss = 2.629\n",
            "Step 2000, Training Loss = 0.945, Test Loss = 2.387\n",
            "Step 2100, Training Loss = 1.581, Test Loss = 2.300\n",
            "Step 2200, Training Loss = 1.991, Test Loss = 2.425\n",
            "Step 2300, Training Loss = 2.571, Test Loss = 2.010\n",
            "Step 2400, Training Loss = 1.474, Test Loss = 2.300\n",
            "Step 2500, Training Loss = 1.641, Test Loss = 2.095\n",
            "Step 2600, Training Loss = 1.597, Test Loss = 2.431\n",
            "Step 2700, Training Loss = 1.230, Test Loss = 2.281\n",
            "Step 2800, Training Loss = 1.215, Test Loss = 2.508\n",
            "Step 2900, Training Loss = 1.329, Test Loss = 2.500\n",
            "Step 3000, Training Loss = 1.219, Test Loss = 2.313\n",
            "Step 3100, Training Loss = 2.253, Test Loss = 2.220\n",
            "Step 3200, Training Loss = 1.063, Test Loss = 2.271\n",
            "Step 3300, Training Loss = 1.226, Test Loss = 2.325\n",
            "Step 3400, Training Loss = 0.881, Test Loss = 2.080\n",
            "Step 3500, Training Loss = 2.232, Test Loss = 2.430\n",
            "Step 3600, Training Loss = 1.786, Test Loss = 2.580\n",
            "Step 3700, Training Loss = 1.310, Test Loss = 2.418\n",
            "Step 3800, Training Loss = 1.249, Test Loss = 2.185\n",
            "Step 3900, Training Loss = 1.302, Test Loss = 2.199\n",
            "Step 4000, Training Loss = 1.579, Test Loss = 2.139\n",
            "Step 4100, Training Loss = 1.103, Test Loss = 2.383\n",
            "Step 4200, Training Loss = 2.014, Test Loss = 2.360\n",
            "Step 4300, Training Loss = 1.494, Test Loss = 2.172\n",
            "Step 4400, Training Loss = 1.693, Test Loss = 2.079\n",
            "Step 4500, Training Loss = 1.280, Test Loss = 2.379\n",
            "Step 4600, Training Loss = 1.594, Test Loss = 2.060\n",
            "TOTAL TRAINING LOSS 6413.498\n",
            "Step 0, Training Loss = 1.136, Test Loss = 2.293\n",
            "Step 1, Training Loss = 1.396, Test Loss = 2.307\n",
            "Step 100, Training Loss = 1.486, Test Loss = 2.374\n",
            "Step 200, Training Loss = 1.638, Test Loss = 2.048\n",
            "Step 300, Training Loss = 0.884, Test Loss = 1.871\n",
            "Step 400, Training Loss = 1.377, Test Loss = 2.225\n",
            "Step 500, Training Loss = 1.779, Test Loss = 2.149\n",
            "Step 600, Training Loss = 1.991, Test Loss = 2.015\n",
            "Step 700, Training Loss = 1.492, Test Loss = 2.450\n",
            "Step 800, Training Loss = 1.307, Test Loss = 2.165\n",
            "Step 900, Training Loss = 1.253, Test Loss = 2.277\n",
            "Step 1000, Training Loss = 1.146, Test Loss = 2.255\n",
            "Step 1100, Training Loss = 1.325, Test Loss = 2.228\n",
            "Step 1200, Training Loss = 1.120, Test Loss = 2.248\n",
            "Step 1300, Training Loss = 1.204, Test Loss = 2.183\n",
            "Step 1400, Training Loss = 1.495, Test Loss = 2.228\n",
            "Step 1500, Training Loss = 1.719, Test Loss = 2.740\n",
            "Step 1600, Training Loss = 1.711, Test Loss = 2.472\n",
            "Step 1700, Training Loss = 1.416, Test Loss = 2.543\n",
            "Step 1800, Training Loss = 2.238, Test Loss = 2.443\n",
            "Step 1900, Training Loss = 1.602, Test Loss = 1.977\n",
            "Step 2000, Training Loss = 1.605, Test Loss = 2.362\n",
            "Step 2100, Training Loss = 1.010, Test Loss = 2.174\n",
            "Step 2200, Training Loss = 1.378, Test Loss = 2.542\n",
            "Step 2300, Training Loss = 1.217, Test Loss = 2.271\n",
            "Step 2400, Training Loss = 1.426, Test Loss = 1.791\n",
            "Step 2500, Training Loss = 1.597, Test Loss = 2.152\n",
            "Step 2600, Training Loss = 1.506, Test Loss = 2.211\n",
            "Step 2700, Training Loss = 0.947, Test Loss = 1.980\n",
            "Step 2800, Training Loss = 1.755, Test Loss = 1.980\n",
            "Step 2900, Training Loss = 1.251, Test Loss = 2.411\n",
            "Step 3000, Training Loss = 1.132, Test Loss = 1.959\n",
            "Step 3100, Training Loss = 1.108, Test Loss = 2.681\n",
            "Step 3200, Training Loss = 1.828, Test Loss = 2.529\n",
            "Step 3300, Training Loss = 1.335, Test Loss = 2.518\n",
            "Step 3400, Training Loss = 1.424, Test Loss = 2.425\n",
            "Step 3500, Training Loss = 1.108, Test Loss = 2.210\n",
            "Step 3600, Training Loss = 1.153, Test Loss = 2.433\n",
            "Step 3700, Training Loss = 1.185, Test Loss = 2.717\n",
            "Step 3800, Training Loss = 2.228, Test Loss = 2.372\n",
            "Step 3900, Training Loss = 0.827, Test Loss = 2.401\n",
            "Step 4000, Training Loss = 1.153, Test Loss = 2.422\n",
            "Step 4100, Training Loss = 1.072, Test Loss = 2.421\n",
            "Step 4200, Training Loss = 2.012, Test Loss = 2.587\n",
            "Step 4300, Training Loss = 1.749, Test Loss = 2.344\n",
            "Step 4400, Training Loss = 1.888, Test Loss = 2.307\n",
            "Step 4500, Training Loss = 1.817, Test Loss = 2.313\n",
            "Step 4600, Training Loss = 1.809, Test Loss = 1.972\n",
            "TOTAL TRAINING LOSS 6287.761\n",
            "Step 0, Training Loss = 0.806, Test Loss = 2.158\n",
            "Step 1, Training Loss = 1.214, Test Loss = 2.146\n",
            "Step 100, Training Loss = 1.052, Test Loss = 2.189\n",
            "Step 200, Training Loss = 1.041, Test Loss = 2.426\n",
            "Step 300, Training Loss = 1.154, Test Loss = 2.200\n",
            "Step 400, Training Loss = 1.236, Test Loss = 2.178\n",
            "Step 500, Training Loss = 1.692, Test Loss = 2.245\n",
            "Step 600, Training Loss = 1.399, Test Loss = 2.340\n",
            "Step 700, Training Loss = 0.953, Test Loss = 2.316\n",
            "Step 800, Training Loss = 1.361, Test Loss = 2.069\n",
            "Step 900, Training Loss = 1.847, Test Loss = 2.583\n",
            "Step 1000, Training Loss = 1.532, Test Loss = 2.398\n",
            "Step 1100, Training Loss = 0.963, Test Loss = 2.297\n",
            "Step 1200, Training Loss = 1.327, Test Loss = 2.478\n",
            "Step 1300, Training Loss = 1.378, Test Loss = 2.479\n",
            "Step 1400, Training Loss = 1.561, Test Loss = 2.152\n",
            "Step 1500, Training Loss = 1.557, Test Loss = 2.295\n",
            "Step 1600, Training Loss = 1.615, Test Loss = 2.332\n",
            "Step 1700, Training Loss = 1.162, Test Loss = 2.388\n",
            "Step 1800, Training Loss = 0.851, Test Loss = 2.118\n",
            "Step 1900, Training Loss = 1.173, Test Loss = 2.323\n",
            "Step 2000, Training Loss = 0.848, Test Loss = 2.353\n",
            "Step 2100, Training Loss = 1.503, Test Loss = 2.299\n",
            "Step 2200, Training Loss = 1.491, Test Loss = 2.384\n",
            "Step 2300, Training Loss = 1.575, Test Loss = 2.374\n",
            "Step 2400, Training Loss = 1.609, Test Loss = 2.335\n",
            "Step 2500, Training Loss = 1.446, Test Loss = 1.872\n",
            "Step 2600, Training Loss = 1.145, Test Loss = 1.733\n",
            "Step 2700, Training Loss = 1.226, Test Loss = 1.924\n",
            "Step 2800, Training Loss = 1.708, Test Loss = 2.093\n",
            "Step 2900, Training Loss = 0.957, Test Loss = 2.443\n",
            "Step 3000, Training Loss = 0.881, Test Loss = 2.495\n",
            "Step 3100, Training Loss = 1.257, Test Loss = 2.291\n",
            "Step 3200, Training Loss = 1.660, Test Loss = 2.439\n",
            "Step 3300, Training Loss = 0.890, Test Loss = 2.230\n",
            "Step 3400, Training Loss = 1.577, Test Loss = 2.264\n",
            "Step 3500, Training Loss = 1.770, Test Loss = 2.258\n",
            "Step 3600, Training Loss = 1.389, Test Loss = 1.968\n",
            "Step 3700, Training Loss = 1.629, Test Loss = 2.334\n",
            "Step 3800, Training Loss = 1.159, Test Loss = 2.716\n",
            "Step 3900, Training Loss = 1.575, Test Loss = 2.427\n",
            "Step 4000, Training Loss = 1.087, Test Loss = 2.529\n",
            "Step 4100, Training Loss = 1.702, Test Loss = 2.220\n",
            "Step 4200, Training Loss = 1.955, Test Loss = 2.021\n",
            "Step 4300, Training Loss = 0.877, Test Loss = 1.960\n",
            "Step 4400, Training Loss = 1.668, Test Loss = 2.082\n",
            "Step 4500, Training Loss = 1.298, Test Loss = 2.243\n",
            "Step 4600, Training Loss = 1.299, Test Loss = 1.821\n",
            "TOTAL TRAINING LOSS 6203.763\n",
            "Step 0, Training Loss = 1.460, Test Loss = 2.123\n",
            "Step 1, Training Loss = 1.737, Test Loss = 2.129\n",
            "Step 100, Training Loss = 1.076, Test Loss = 2.226\n",
            "Step 200, Training Loss = 1.610, Test Loss = 2.145\n",
            "Step 300, Training Loss = 1.561, Test Loss = 2.685\n",
            "Step 400, Training Loss = 1.446, Test Loss = 1.931\n",
            "Step 500, Training Loss = 1.299, Test Loss = 1.988\n",
            "Step 600, Training Loss = 1.957, Test Loss = 2.140\n",
            "Step 700, Training Loss = 1.553, Test Loss = 1.945\n",
            "Step 800, Training Loss = 1.086, Test Loss = 2.030\n",
            "Step 900, Training Loss = 1.256, Test Loss = 2.176\n",
            "Step 1000, Training Loss = 1.598, Test Loss = 1.921\n",
            "Step 1100, Training Loss = 1.184, Test Loss = 1.947\n",
            "Step 1200, Training Loss = 1.389, Test Loss = 2.110\n",
            "Step 1300, Training Loss = 1.767, Test Loss = 2.226\n",
            "Step 1400, Training Loss = 1.144, Test Loss = 2.519\n",
            "Step 1500, Training Loss = 1.598, Test Loss = 2.239\n",
            "Step 1600, Training Loss = 1.357, Test Loss = 2.042\n",
            "Step 1700, Training Loss = 0.891, Test Loss = 2.107\n",
            "Step 1800, Training Loss = 0.993, Test Loss = 2.296\n",
            "Step 1900, Training Loss = 0.967, Test Loss = 2.255\n",
            "Step 2000, Training Loss = 1.850, Test Loss = 2.346\n",
            "Step 2100, Training Loss = 1.360, Test Loss = 2.221\n",
            "Step 2200, Training Loss = 1.205, Test Loss = 2.316\n",
            "Step 2300, Training Loss = 1.228, Test Loss = 2.444\n",
            "Step 2400, Training Loss = 1.663, Test Loss = 2.368\n",
            "Step 2500, Training Loss = 1.495, Test Loss = 2.410\n",
            "Step 2600, Training Loss = 1.459, Test Loss = 2.670\n",
            "Step 2700, Training Loss = 1.319, Test Loss = 2.229\n",
            "Step 2800, Training Loss = 1.231, Test Loss = 2.300\n",
            "Step 2900, Training Loss = 1.224, Test Loss = 2.130\n",
            "Step 3000, Training Loss = 1.606, Test Loss = 2.214\n",
            "Step 3100, Training Loss = 0.909, Test Loss = 2.106\n",
            "Step 3200, Training Loss = 1.292, Test Loss = 2.102\n",
            "Step 3300, Training Loss = 0.798, Test Loss = 2.425\n",
            "Step 3400, Training Loss = 1.079, Test Loss = 2.084\n",
            "Step 3500, Training Loss = 1.676, Test Loss = 2.712\n",
            "Step 3600, Training Loss = 1.412, Test Loss = 2.453\n",
            "Step 3700, Training Loss = 1.637, Test Loss = 2.119\n",
            "Step 3800, Training Loss = 0.996, Test Loss = 1.957\n",
            "Step 3900, Training Loss = 1.581, Test Loss = 2.247\n",
            "Step 4000, Training Loss = 1.037, Test Loss = 1.977\n",
            "Step 4100, Training Loss = 1.961, Test Loss = 1.990\n",
            "Step 4200, Training Loss = 1.125, Test Loss = 1.904\n",
            "Step 4300, Training Loss = 1.367, Test Loss = 2.144\n",
            "Step 4400, Training Loss = 1.140, Test Loss = 2.330\n",
            "Step 4500, Training Loss = 1.419, Test Loss = 2.630\n",
            "Step 4600, Training Loss = 1.511, Test Loss = 2.147\n",
            "TOTAL TRAINING LOSS 6111.492\n",
            "Step 0, Training Loss = 1.090, Test Loss = 2.292\n",
            "Step 1, Training Loss = 1.354, Test Loss = 2.302\n",
            "Step 100, Training Loss = 1.118, Test Loss = 2.697\n",
            "Step 200, Training Loss = 0.858, Test Loss = 2.294\n",
            "Step 300, Training Loss = 0.863, Test Loss = 2.182\n",
            "Step 400, Training Loss = 0.758, Test Loss = 2.417\n",
            "Step 500, Training Loss = 1.187, Test Loss = 2.433\n",
            "Step 600, Training Loss = 1.011, Test Loss = 2.322\n",
            "Step 700, Training Loss = 1.379, Test Loss = 2.245\n",
            "Step 800, Training Loss = 2.108, Test Loss = 2.313\n",
            "Step 900, Training Loss = 0.924, Test Loss = 2.428\n",
            "Step 1000, Training Loss = 1.014, Test Loss = 2.278\n",
            "Step 1100, Training Loss = 1.443, Test Loss = 2.395\n",
            "Step 1200, Training Loss = 1.041, Test Loss = 2.101\n",
            "Step 1300, Training Loss = 1.942, Test Loss = 2.610\n",
            "Step 1400, Training Loss = 1.396, Test Loss = 2.165\n",
            "Step 1500, Training Loss = 2.008, Test Loss = 2.029\n",
            "Step 1600, Training Loss = 1.487, Test Loss = 2.226\n",
            "Step 1700, Training Loss = 1.299, Test Loss = 2.280\n",
            "Step 1800, Training Loss = 0.725, Test Loss = 2.524\n",
            "Step 1900, Training Loss = 1.097, Test Loss = 2.572\n",
            "Step 2000, Training Loss = 1.013, Test Loss = 2.532\n",
            "Step 2100, Training Loss = 0.906, Test Loss = 2.478\n",
            "Step 2200, Training Loss = 1.029, Test Loss = 2.327\n",
            "Step 2300, Training Loss = 1.563, Test Loss = 2.540\n",
            "Step 2400, Training Loss = 0.901, Test Loss = 1.993\n",
            "Step 2500, Training Loss = 0.867, Test Loss = 2.081\n",
            "Step 2600, Training Loss = 1.533, Test Loss = 2.307\n",
            "Step 2700, Training Loss = 0.988, Test Loss = 2.275\n",
            "Step 2800, Training Loss = 1.425, Test Loss = 2.433\n",
            "Step 2900, Training Loss = 1.254, Test Loss = 2.189\n",
            "Step 3000, Training Loss = 1.228, Test Loss = 2.065\n",
            "Step 3100, Training Loss = 1.169, Test Loss = 1.961\n",
            "Step 3200, Training Loss = 2.952, Test Loss = 2.014\n",
            "Step 3300, Training Loss = 2.290, Test Loss = 2.199\n",
            "Step 3400, Training Loss = 1.827, Test Loss = 2.197\n",
            "Step 3500, Training Loss = 1.239, Test Loss = 2.167\n",
            "Step 3600, Training Loss = 1.021, Test Loss = 2.254\n",
            "Step 3700, Training Loss = 0.874, Test Loss = 2.207\n",
            "Step 3800, Training Loss = 1.325, Test Loss = 2.031\n",
            "Step 3900, Training Loss = 1.451, Test Loss = 2.143\n",
            "Step 4000, Training Loss = 0.794, Test Loss = 2.415\n",
            "Step 4100, Training Loss = 1.342, Test Loss = 2.456\n",
            "Step 4200, Training Loss = 0.779, Test Loss = 2.479\n",
            "Step 4300, Training Loss = 1.068, Test Loss = 2.321\n",
            "Step 4400, Training Loss = 1.147, Test Loss = 1.932\n",
            "Step 4500, Training Loss = 1.067, Test Loss = 1.914\n",
            "Step 4600, Training Loss = 0.871, Test Loss = 2.098\n",
            "TOTAL TRAINING LOSS 6005.164\n",
            "Step 0, Training Loss = 0.828, Test Loss = 2.154\n",
            "Step 1, Training Loss = 1.628, Test Loss = 2.151\n",
            "Step 100, Training Loss = 0.903, Test Loss = 2.314\n",
            "Step 200, Training Loss = 0.863, Test Loss = 2.328\n",
            "Step 300, Training Loss = 1.736, Test Loss = 2.035\n",
            "Step 400, Training Loss = 0.972, Test Loss = 2.084\n",
            "Step 500, Training Loss = 0.890, Test Loss = 2.091\n",
            "Step 600, Training Loss = 0.900, Test Loss = 2.311\n",
            "Step 700, Training Loss = 1.147, Test Loss = 1.961\n",
            "Step 800, Training Loss = 1.659, Test Loss = 2.234\n",
            "Step 900, Training Loss = 1.113, Test Loss = 2.241\n",
            "Step 1000, Training Loss = 1.550, Test Loss = 2.166\n",
            "Step 1100, Training Loss = 1.054, Test Loss = 2.204\n",
            "Step 1200, Training Loss = 1.188, Test Loss = 2.131\n",
            "Step 1300, Training Loss = 0.875, Test Loss = 2.250\n",
            "Step 1400, Training Loss = 1.026, Test Loss = 2.266\n",
            "Step 1500, Training Loss = 1.075, Test Loss = 2.339\n",
            "Step 1600, Training Loss = 1.642, Test Loss = 2.199\n",
            "Step 1700, Training Loss = 1.515, Test Loss = 2.292\n",
            "Step 1800, Training Loss = 1.488, Test Loss = 2.131\n",
            "Step 1900, Training Loss = 1.202, Test Loss = 2.520\n",
            "Step 2000, Training Loss = 0.869, Test Loss = 2.187\n",
            "Step 2100, Training Loss = 1.176, Test Loss = 2.018\n",
            "Step 2200, Training Loss = 1.132, Test Loss = 1.964\n",
            "Step 2300, Training Loss = 1.219, Test Loss = 1.932\n",
            "Step 2400, Training Loss = 1.424, Test Loss = 1.711\n",
            "Step 2500, Training Loss = 1.495, Test Loss = 1.799\n",
            "Step 2600, Training Loss = 0.675, Test Loss = 2.102\n",
            "Step 2700, Training Loss = 1.053, Test Loss = 2.090\n",
            "Step 2800, Training Loss = 1.551, Test Loss = 1.990\n",
            "Step 2900, Training Loss = 0.932, Test Loss = 2.411\n",
            "Step 3000, Training Loss = 1.134, Test Loss = 2.215\n",
            "Step 3100, Training Loss = 1.083, Test Loss = 2.264\n",
            "Step 3200, Training Loss = 1.023, Test Loss = 2.202\n",
            "Step 3300, Training Loss = 1.275, Test Loss = 2.219\n",
            "Step 3400, Training Loss = 0.888, Test Loss = 2.151\n",
            "Step 3500, Training Loss = 0.846, Test Loss = 2.256\n",
            "Step 3600, Training Loss = 1.771, Test Loss = 2.506\n",
            "Step 3700, Training Loss = 2.105, Test Loss = 2.039\n",
            "Step 3800, Training Loss = 0.999, Test Loss = 1.987\n",
            "Step 3900, Training Loss = 1.254, Test Loss = 2.281\n",
            "Step 4000, Training Loss = 1.393, Test Loss = 2.456\n",
            "Step 4100, Training Loss = 1.122, Test Loss = 2.709\n",
            "Step 4200, Training Loss = 1.173, Test Loss = 2.542\n",
            "Step 4300, Training Loss = 1.006, Test Loss = 2.412\n",
            "Step 4400, Training Loss = 1.147, Test Loss = 2.707\n",
            "Step 4500, Training Loss = 0.875, Test Loss = 2.369\n",
            "Step 4600, Training Loss = 0.703, Test Loss = 2.585\n",
            "TOTAL TRAINING LOSS 5919.276\n",
            "Step 0, Training Loss = 0.598, Test Loss = 2.305\n",
            "Step 1, Training Loss = 1.151, Test Loss = 2.305\n",
            "Step 100, Training Loss = 1.071, Test Loss = 2.407\n",
            "Step 200, Training Loss = 1.437, Test Loss = 2.445\n",
            "Step 300, Training Loss = 1.327, Test Loss = 2.475\n",
            "Step 400, Training Loss = 1.415, Test Loss = 2.269\n",
            "Step 500, Training Loss = 1.307, Test Loss = 2.608\n",
            "Step 600, Training Loss = 1.720, Test Loss = 2.269\n",
            "Step 700, Training Loss = 1.010, Test Loss = 2.186\n",
            "Step 800, Training Loss = 1.172, Test Loss = 1.863\n",
            "Step 900, Training Loss = 1.610, Test Loss = 2.143\n",
            "Step 1000, Training Loss = 1.367, Test Loss = 2.333\n",
            "Step 1100, Training Loss = 1.783, Test Loss = 2.574\n",
            "Step 1200, Training Loss = 0.887, Test Loss = 2.411\n",
            "Step 1300, Training Loss = 1.720, Test Loss = 2.082\n",
            "Step 1400, Training Loss = 1.557, Test Loss = 2.399\n",
            "Step 1500, Training Loss = 0.857, Test Loss = 2.396\n",
            "Step 1600, Training Loss = 1.096, Test Loss = 2.288\n",
            "Step 1700, Training Loss = 0.874, Test Loss = 2.206\n",
            "Step 1800, Training Loss = 0.978, Test Loss = 2.216\n",
            "Step 1900, Training Loss = 1.322, Test Loss = 2.026\n",
            "Step 2000, Training Loss = 1.144, Test Loss = 2.266\n",
            "Step 2100, Training Loss = 0.979, Test Loss = 2.181\n",
            "Step 2200, Training Loss = 1.185, Test Loss = 2.175\n",
            "Step 2300, Training Loss = 0.854, Test Loss = 2.149\n",
            "Step 2400, Training Loss = 1.364, Test Loss = 2.107\n",
            "Step 2500, Training Loss = 0.874, Test Loss = 2.293\n",
            "Step 2600, Training Loss = 1.974, Test Loss = 2.279\n",
            "Step 2700, Training Loss = 1.273, Test Loss = 2.280\n",
            "Step 2800, Training Loss = 1.091, Test Loss = 2.259\n",
            "Step 2900, Training Loss = 1.490, Test Loss = 2.354\n",
            "Step 3000, Training Loss = 1.367, Test Loss = 1.996\n",
            "Step 3100, Training Loss = 1.476, Test Loss = 2.472\n",
            "Step 3200, Training Loss = 2.007, Test Loss = 2.238\n",
            "Step 3300, Training Loss = 0.918, Test Loss = 2.240\n",
            "Step 3400, Training Loss = 1.321, Test Loss = 2.362\n",
            "Step 3500, Training Loss = 1.501, Test Loss = 2.127\n",
            "Step 3600, Training Loss = 1.262, Test Loss = 2.093\n",
            "Step 3700, Training Loss = 1.287, Test Loss = 2.144\n",
            "Step 3800, Training Loss = 1.845, Test Loss = 2.102\n",
            "Step 3900, Training Loss = 1.318, Test Loss = 2.290\n",
            "Step 4000, Training Loss = 1.232, Test Loss = 2.184\n",
            "Step 4100, Training Loss = 1.377, Test Loss = 1.979\n",
            "Step 4200, Training Loss = 0.556, Test Loss = 2.198\n",
            "Step 4300, Training Loss = 1.728, Test Loss = 2.508\n",
            "Step 4400, Training Loss = 0.970, Test Loss = 2.303\n",
            "Step 4500, Training Loss = 1.184, Test Loss = 1.958\n",
            "Step 4600, Training Loss = 1.134, Test Loss = 2.273\n",
            "TOTAL TRAINING LOSS 5835.150\n",
            "Step 0, Training Loss = 1.337, Test Loss = 1.990\n",
            "Step 1, Training Loss = 1.241, Test Loss = 2.007\n",
            "Step 100, Training Loss = 1.251, Test Loss = 2.068\n",
            "Step 200, Training Loss = 1.346, Test Loss = 2.066\n",
            "Step 300, Training Loss = 2.043, Test Loss = 1.936\n",
            "Step 400, Training Loss = 0.775, Test Loss = 2.434\n",
            "Step 500, Training Loss = 1.215, Test Loss = 2.015\n",
            "Step 600, Training Loss = 1.737, Test Loss = 2.170\n",
            "Step 700, Training Loss = 0.810, Test Loss = 2.109\n",
            "Step 800, Training Loss = 1.736, Test Loss = 2.395\n",
            "Step 900, Training Loss = 0.943, Test Loss = 1.927\n",
            "Step 1000, Training Loss = 1.011, Test Loss = 2.082\n",
            "Step 1100, Training Loss = 1.220, Test Loss = 2.178\n",
            "Step 1200, Training Loss = 1.485, Test Loss = 2.159\n",
            "Step 1300, Training Loss = 1.093, Test Loss = 2.197\n",
            "Step 1400, Training Loss = 1.262, Test Loss = 2.534\n",
            "Step 1500, Training Loss = 1.593, Test Loss = 2.496\n",
            "Step 1600, Training Loss = 1.821, Test Loss = 2.633\n",
            "Step 1700, Training Loss = 1.133, Test Loss = 2.245\n",
            "Step 1800, Training Loss = 1.734, Test Loss = 1.876\n",
            "Step 1900, Training Loss = 1.372, Test Loss = 2.183\n",
            "Step 2000, Training Loss = 0.824, Test Loss = 2.405\n",
            "Step 2100, Training Loss = 0.829, Test Loss = 2.195\n",
            "Step 2200, Training Loss = 1.363, Test Loss = 2.211\n",
            "Step 2300, Training Loss = 1.336, Test Loss = 2.214\n",
            "Step 2400, Training Loss = 1.287, Test Loss = 2.365\n",
            "Step 2500, Training Loss = 1.832, Test Loss = 2.243\n",
            "Step 2600, Training Loss = 1.448, Test Loss = 2.233\n",
            "Step 2700, Training Loss = 2.049, Test Loss = 2.356\n",
            "Step 2800, Training Loss = 1.117, Test Loss = 2.063\n",
            "Step 2900, Training Loss = 1.942, Test Loss = 2.342\n",
            "Step 3000, Training Loss = 1.459, Test Loss = 2.223\n",
            "Step 3100, Training Loss = 1.123, Test Loss = 2.111\n",
            "Step 3200, Training Loss = 1.036, Test Loss = 2.295\n",
            "Step 3300, Training Loss = 0.778, Test Loss = 1.990\n",
            "Step 3400, Training Loss = 1.660, Test Loss = 2.404\n",
            "Step 3500, Training Loss = 1.240, Test Loss = 2.523\n",
            "Step 3600, Training Loss = 0.749, Test Loss = 2.343\n",
            "Step 3700, Training Loss = 1.187, Test Loss = 2.323\n",
            "Step 3800, Training Loss = 1.804, Test Loss = 2.048\n",
            "Step 3900, Training Loss = 1.029, Test Loss = 2.061\n",
            "Step 4000, Training Loss = 1.127, Test Loss = 2.223\n",
            "Step 4100, Training Loss = 1.201, Test Loss = 2.235\n",
            "Step 4200, Training Loss = 1.703, Test Loss = 2.263\n",
            "Step 4300, Training Loss = 0.813, Test Loss = 2.466\n",
            "Step 4400, Training Loss = 1.115, Test Loss = 2.275\n",
            "Step 4500, Training Loss = 1.532, Test Loss = 2.086\n",
            "Step 4600, Training Loss = 1.294, Test Loss = 2.206\n",
            "TOTAL TRAINING LOSS 5756.552\n",
            "Step 0, Training Loss = 0.905, Test Loss = 2.619\n",
            "Step 1, Training Loss = 0.984, Test Loss = 2.637\n",
            "Step 100, Training Loss = 1.451, Test Loss = 2.122\n",
            "Step 200, Training Loss = 0.867, Test Loss = 2.366\n",
            "Step 300, Training Loss = 1.746, Test Loss = 2.251\n",
            "Step 400, Training Loss = 0.811, Test Loss = 2.157\n",
            "Step 500, Training Loss = 0.966, Test Loss = 2.354\n",
            "Step 600, Training Loss = 0.929, Test Loss = 2.275\n",
            "Step 700, Training Loss = 1.005, Test Loss = 2.576\n",
            "Step 800, Training Loss = 1.261, Test Loss = 2.296\n",
            "Step 900, Training Loss = 1.051, Test Loss = 2.347\n",
            "Step 1000, Training Loss = 1.605, Test Loss = 2.116\n",
            "Step 1100, Training Loss = 0.837, Test Loss = 2.262\n",
            "Step 1200, Training Loss = 0.901, Test Loss = 2.187\n",
            "Step 1300, Training Loss = 0.815, Test Loss = 2.166\n",
            "Step 1400, Training Loss = 1.086, Test Loss = 2.299\n",
            "Step 1500, Training Loss = 1.211, Test Loss = 2.510\n",
            "Step 1600, Training Loss = 0.991, Test Loss = 2.329\n",
            "Step 1700, Training Loss = 0.938, Test Loss = 2.203\n",
            "Step 1800, Training Loss = 0.906, Test Loss = 2.158\n",
            "Step 1900, Training Loss = 1.121, Test Loss = 2.129\n",
            "Step 2000, Training Loss = 1.409, Test Loss = 2.624\n",
            "Step 2100, Training Loss = 1.025, Test Loss = 2.444\n",
            "Step 2200, Training Loss = 0.855, Test Loss = 2.454\n",
            "Step 2300, Training Loss = 1.040, Test Loss = 2.274\n",
            "Step 2400, Training Loss = 1.764, Test Loss = 2.263\n",
            "Step 2500, Training Loss = 0.975, Test Loss = 2.631\n",
            "Step 2600, Training Loss = 0.798, Test Loss = 2.185\n",
            "Step 2700, Training Loss = 1.672, Test Loss = 2.146\n",
            "Step 2800, Training Loss = 1.244, Test Loss = 2.157\n",
            "Step 2900, Training Loss = 2.777, Test Loss = 2.275\n",
            "Step 3000, Training Loss = 1.347, Test Loss = 2.339\n",
            "Step 3100, Training Loss = 0.535, Test Loss = 1.887\n",
            "Step 3200, Training Loss = 1.614, Test Loss = 1.889\n",
            "Step 3300, Training Loss = 1.083, Test Loss = 2.004\n",
            "Step 3400, Training Loss = 1.012, Test Loss = 2.107\n",
            "Step 3500, Training Loss = 1.365, Test Loss = 2.076\n",
            "Step 3600, Training Loss = 1.301, Test Loss = 2.374\n",
            "Step 3700, Training Loss = 1.689, Test Loss = 2.256\n",
            "Step 3800, Training Loss = 1.008, Test Loss = 2.452\n",
            "Step 3900, Training Loss = 1.303, Test Loss = 2.002\n",
            "Step 4000, Training Loss = 1.424, Test Loss = 2.166\n",
            "Step 4100, Training Loss = 1.256, Test Loss = 2.261\n",
            "Step 4200, Training Loss = 1.475, Test Loss = 2.086\n",
            "Step 4300, Training Loss = 0.917, Test Loss = 2.077\n",
            "Step 4400, Training Loss = 1.165, Test Loss = 2.055\n",
            "Step 4500, Training Loss = 0.810, Test Loss = 2.247\n",
            "Step 4600, Training Loss = 1.101, Test Loss = 2.114\n",
            "TOTAL TRAINING LOSS 5661.096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aQ5lb1Hy6OR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "5b4d0f51-88de-4745-aaab-9d0f1a823f3a"
      },
      "source": [
        "mca_ic50.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"i_c50_mca\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "repeat_vector_1 (RepeatVecto multiple                  0         \n",
            "_________________________________________________________________\n",
            "contextual_attention_layer ( multiple                  609281    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             multiple                  9359360   \n",
            "_________________________________________________________________\n",
            "dense_attention_layer (Dense multiple                  4530512   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             multiple                  2098176   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             multiple                  524800    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                multiple                  312744    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             multiple                  513       \n",
            "=================================================================\n",
            "Total params: 17,435,386\n",
            "Trainable params: 17,435,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}